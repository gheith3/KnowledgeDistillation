{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Knowledge Distillation for EfficientNetV2 on CIFAR-100 - Version 4 (Grand Finale)\n",
        "\n",
        "This notebook implements the **\"Best of Both Worlds\"** approach:\n",
        "\n",
        "- **Best Teacher:** Teacher v3 (76.02% accuracy)\n",
        "- **Best Distillation:** Standard KD (v2 pipeline with 98% retention rate)\n",
        "\n",
        "---\n",
        "\n",
        "## Version History:\n",
        "\n",
        "- **v1 (Baseline):** Standard KD + CutMix/Mixup → 72.34% accuracy\n",
        "- **v2 (Enhanced):** + AutoAugment + Label Smoothing + LR Warmup → 74.20% accuracy (98% retention)\n",
        "- **v3 (DKD β=8.0):** Decoupled KD → 72.69% (over-regularized)\n",
        "- **v3.1 (DKD β=2.0):** Tuned DKD → 73.98% (97.3% retention)\n",
        "- **v4 (Grand Finale):** Strong Teacher v3 + Standard KD → Target: **74.50%+**\n",
        "\n",
        "---\n",
        "\n",
        "## Key Strategy in v4:\n",
        "\n",
        "1. **Use Teacher v3** (76.02%) - the strongest teacher we have\n",
        "2. **Revert to Standard KD** (not DKD) - proven 98% retention rate with augmentation\n",
        "3. **Keep v2 augmentation pipeline** - AutoAugment + Mixup/CutMix + Label Smoothing\n",
        "\n",
        "**Prediction:** 76.02% × 0.98 ≈ **74.50%** (new record!)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directories ready at: d:\\Projects\\MasterProject\\code\\outputs\n",
            "Using device: cuda\n",
            "GPU: NVIDIA GeForce RTX 5070 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup and Imports\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import efficientnet_v2_s, efficientnet_v2_l, EfficientNet_V2_S_Weights, EfficientNet_V2_L_Weights\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup Directories (Local paths)\n",
        "PROJECT_ROOT = Path('./outputs')\n",
        "MODEL_DIR = PROJECT_ROOT / 'models'\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "CHECKPOINT_DIR = PROJECT_ROOT / 'checkpoints'\n",
        "\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Directories ready at: {PROJECT_ROOT.absolute()}\")\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "VERSION 4 CONFIG - Grand Finale (Best Teacher + Best KD)\n",
            "============================================================\n",
            "Strategy: Strong Teacher v3 + Standard KD (v2 pipeline)\n",
            "Teacher: teacher_v3 (Accuracy: 76.02%)\n",
            "Training: Epochs=200 | Batch=128 | LR=0.001\n",
            "Standard KD: Alpha=0.7, Temp=4.0 (NOT DKD)\n",
            "Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\n",
            "Student Model: student_v4_standard_kd\n",
            "Expected: 76.02% × 0.98 ≈ 74.50%\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Experiment Configuration (Version 4 - Grand Finale)\n",
        "# ==========================================\n",
        "# HYPERPARAMETERS\n",
        "# ==========================================\n",
        "NUM_EPOCHS = 200\n",
        "TEACHER_EPOCHS = 300\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.05\n",
        "PATIENCE = 30\n",
        "WARMUP_EPOCHS = 5           # LR warmup\n",
        "\n",
        "# Distillation Params (Standard KD - v2 settings, NOT DKD)\n",
        "KD_ALPHA = 0.7              # Soft loss weight (v2 setting)\n",
        "TEMPERATURE = 4.0           # Softmax Temperature\n",
        "LABEL_SMOOTHING = 0.1       # Label smoothing for hard loss\n",
        "\n",
        "# Augmentation Params (same as v2)\n",
        "MIXUP_ALPHA = 0.8\n",
        "CUTMIX_ALPHA = 1.0\n",
        "CHECKPOINT_FREQUENCY = 20\n",
        "NUM_CLASSES = 100\n",
        "\n",
        "# Version 4 Model Names\n",
        "TEACHER_NAME = \"teacher_v3\"              # Use the STRONG teacher (76.02%)\n",
        "STUDENT_NAME = \"student_v4_standard_kd\"  # New student with Standard KD\n",
        "\n",
        "# Flag to use Standard KD instead of DKD\n",
        "USE_DKD = False  # KEY CHANGE: Disable DKD, use Standard KD\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"VERSION 4 CONFIG - Grand Finale (Best Teacher + Best KD)\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Strategy: Strong Teacher v3 + Standard KD (v2 pipeline)\")\n",
        "print(f\"Teacher: {TEACHER_NAME} (Accuracy: 76.02%)\")\n",
        "print(f\"Training: Epochs={NUM_EPOCHS} | Batch={BATCH_SIZE} | LR={LEARNING_RATE}\")\n",
        "print(f\"Standard KD: Alpha={KD_ALPHA}, Temp={TEMPERATURE} (NOT DKD)\")\n",
        "print(f\"Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\")\n",
        "print(f\"Student Model: {STUDENT_NAME}\")\n",
        "print(f\"Expected: 76.02% × 0.98 ≈ 74.50%\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded: 50000 Training, 10000 Test images\n",
            "  Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Data Loading (Enhanced with AutoAugment + RandomErasing)\n",
        "from torchvision.transforms import autoaugment\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    autoaugment.AutoAugment(policy=autoaugment.AutoAugmentPolicy.CIFAR10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.2)),  # Cutout-like augmentation\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root=str(DATA_DIR), train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, \n",
        "                                          num_workers=4, pin_memory=True, drop_last=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root=str(DATA_DIR), train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, \n",
        "                                         num_workers=4, pin_memory=True)\n",
        "\n",
        "print(f\"Data loaded: {len(trainset)} Training, {len(testset)} Test images\")\n",
        "print(f\"  Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions loaded:\n",
            "  - DKD Loss (Decoupled Knowledge Distillation)\n",
            "  - Standard KD Loss (for comparison)\n",
            "  - CutMix, Mixup augmentations\n",
            "  - Checkpoint utilities\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Helper Functions (DKD Loss + Augmentations + Utilities)\n",
        "\n",
        "# ==========================================\n",
        "# 1. Decoupled Knowledge Distillation (DKD) Loss\n",
        "# Based on: Zhao et al. \"Decoupled Knowledge Distillation\", CVPR 2022\n",
        "# https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Decoupled_Knowledge_Distillation_CVPR_2022_paper.pdf\n",
        "# ==========================================\n",
        "\n",
        "def _get_gt_mask(logits, target):\n",
        "    \"\"\"Get mask for target (ground truth) class\"\"\"\n",
        "    target = target.reshape(-1)\n",
        "    mask = torch.zeros_like(logits).scatter_(1, target.unsqueeze(1), 1).bool()\n",
        "    return mask\n",
        "\n",
        "def _get_other_mask(logits, target):\n",
        "    \"\"\"Get mask for non-target classes\"\"\"\n",
        "    target = target.reshape(-1)\n",
        "    mask = torch.ones_like(logits).scatter_(1, target.unsqueeze(1), 0).bool()\n",
        "    return mask\n",
        "\n",
        "def cat_mask(t, mask1, mask2):\n",
        "    \"\"\"Concatenate masked values\"\"\"\n",
        "    t1 = (t * mask1).sum(dim=1, keepdims=True)\n",
        "    t2 = (t * mask2).sum(1, keepdims=True)\n",
        "    rt = torch.cat([t1, t2], dim=1)\n",
        "    return rt\n",
        "\n",
        "def dkd_loss(student_logits, teacher_logits, target, alpha=1.0, beta=8.0, temperature=4.0):\n",
        "    \"\"\"\n",
        "    Decoupled Knowledge Distillation (DKD) Loss.\n",
        "    \n",
        "    Separates knowledge into:\n",
        "    - TCKD (Target Class Knowledge Distillation): Knowledge about the correct class\n",
        "    - NCKD (Non-Target Class Knowledge Distillation): Knowledge about class relationships\n",
        "    \n",
        "    Args:\n",
        "        student_logits: Student model outputs\n",
        "        teacher_logits: Teacher model outputs\n",
        "        target: Ground truth labels\n",
        "        alpha: Weight for TCKD (default: 1.0)\n",
        "        beta: Weight for NCKD (default: 8.0, crucial for performance)\n",
        "        temperature: Softmax temperature (default: 4.0)\n",
        "    \n",
        "    Returns:\n",
        "        Combined DKD loss\n",
        "    \"\"\"\n",
        "    # Get masks for target and non-target classes\n",
        "    gt_mask = _get_gt_mask(student_logits, target)\n",
        "    other_mask = _get_other_mask(student_logits, target)\n",
        "    \n",
        "    # Calculate probabilities with temperature scaling\n",
        "    pred_student = F.softmax(student_logits / temperature, dim=1)\n",
        "    pred_teacher = F.softmax(teacher_logits / temperature, dim=1)\n",
        "    \n",
        "    # Separate target and non-target probabilities\n",
        "    pred_student_cat = cat_mask(pred_student, gt_mask, other_mask)\n",
        "    pred_teacher_cat = cat_mask(pred_teacher, gt_mask, other_mask)\n",
        "    \n",
        "    # Target Class Knowledge Distillation (TCKD)\n",
        "    log_pred_student = torch.log(pred_student_cat + 1e-8)\n",
        "    tckd_loss = (\n",
        "        F.kl_div(log_pred_student, pred_teacher_cat, reduction='batchmean')\n",
        "        * (temperature ** 2)\n",
        "    )\n",
        "    \n",
        "    # Non-Target Class Knowledge Distillation (NCKD)\n",
        "    # Mask out target class with large negative value\n",
        "    pred_teacher_part2 = F.softmax(\n",
        "        teacher_logits / temperature - 1000.0 * gt_mask, dim=1\n",
        "    )\n",
        "    log_pred_student_part2 = F.log_softmax(\n",
        "        student_logits / temperature - 1000.0 * gt_mask, dim=1\n",
        "    )\n",
        "    \n",
        "    nckd_loss = (\n",
        "        F.kl_div(log_pred_student_part2, pred_teacher_part2, reduction='batchmean')\n",
        "        * (temperature ** 2)\n",
        "    )\n",
        "    \n",
        "    # Combined DKD loss\n",
        "    return alpha * tckd_loss + beta * nckd_loss\n",
        "\n",
        "def dkd_loss_mixup(student_logits, teacher_logits, labels_a, labels_b, lam,\n",
        "                   alpha=1.0, beta=8.0, temperature=4.0, label_smoothing=0.1):\n",
        "    \"\"\"\n",
        "    DKD Loss for mixed samples (CutMix/Mixup compatible)\n",
        "    Uses weighted combination of DKD losses for both label sets\n",
        "    \"\"\"\n",
        "    # DKD for both label sets\n",
        "    dkd_a = dkd_loss(student_logits, teacher_logits, labels_a, alpha, beta, temperature)\n",
        "    dkd_b = dkd_loss(student_logits, teacher_logits, labels_b, alpha, beta, temperature)\n",
        "    \n",
        "    # Weighted DKD loss\n",
        "    soft_loss = lam * dkd_a + (1 - lam) * dkd_b\n",
        "    \n",
        "    # Hard loss with label smoothing\n",
        "    hard_loss = lam * F.cross_entropy(student_logits, labels_a, label_smoothing=label_smoothing) + \\\n",
        "                (1 - lam) * F.cross_entropy(student_logits, labels_b, label_smoothing=label_smoothing)\n",
        "    \n",
        "    # Combined loss (DKD already weighted by alpha/beta, so we just add hard loss)\n",
        "    # Using 0.1 weight for hard loss to not overpower DKD\n",
        "    loss = soft_loss + 0.1 * hard_loss\n",
        "    \n",
        "    # NaN safety check\n",
        "    if torch.isnan(loss):\n",
        "        return hard_loss\n",
        "    \n",
        "    return loss\n",
        "\n",
        "# ==========================================\n",
        "# 2. Standard KD Loss (kept for comparison)\n",
        "# ==========================================\n",
        "def kd_loss(student_logits, teacher_logits, labels, temp=4.0, alpha=0.7, label_smoothing=0.1):\n",
        "    \"\"\"Standard Knowledge Distillation Loss (for comparison)\"\"\"\n",
        "    soft_student = F.log_softmax(student_logits / temp, dim=1)\n",
        "    soft_teacher = F.softmax(teacher_logits / temp, dim=1)\n",
        "    soft_loss = F.kl_div(soft_student, soft_teacher, reduction='batchmean') * (temp ** 2)\n",
        "    hard_loss = F.cross_entropy(student_logits, labels, label_smoothing=label_smoothing)\n",
        "    return alpha * soft_loss + (1 - alpha) * hard_loss\n",
        "\n",
        "# ==========================================\n",
        "# 3. Augmentations: Mixup & CutMix\n",
        "# ==========================================\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = int(W * cut_rat)\n",
        "    cut_h = int(H * cut_rat)\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "def cutmix_data(x, y, alpha=1.0):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
        "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
        "    y_a, y_b = y, y[index]\n",
        "    return x, y_a, y_b, lam\n",
        "\n",
        "# ==========================================\n",
        "# 4. Utilities (Save/Load/Evaluate)\n",
        "# ==========================================\n",
        "def evaluate_model_with_loss(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    acc = 100 * correct / total\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "    return acc, avg_loss\n",
        "\n",
        "def save_checkpoint(model, optimizer, scheduler, epoch, best_acc, history, model_name, epochs_no_improve):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'best_acc': best_acc,\n",
        "        'history': history,\n",
        "        'epochs_no_improve': epochs_no_improve\n",
        "    }\n",
        "    path = CHECKPOINT_DIR / f\"{model_name}_epoch{epoch+1}.pth\"\n",
        "    torch.save(checkpoint, path)\n",
        "    print(f\"  Checkpoint saved: {path}\")\n",
        "    \n",
        "def load_checkpoint(model, optimizer, scheduler, model_name):\n",
        "    checkpoints = sorted(glob.glob(str(CHECKPOINT_DIR / f\"{model_name}_epoch*.pth\")))\n",
        "    if not checkpoints:\n",
        "        return None\n",
        "    latest = checkpoints[-1]\n",
        "    print(f\"  Loading checkpoint: {latest}\")\n",
        "    checkpoint = torch.load(latest, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    return checkpoint\n",
        "\n",
        "def cleanup_old_checkpoints(model_name, keep=3):\n",
        "    checkpoints = sorted(glob.glob(str(CHECKPOINT_DIR / f\"{model_name}_epoch*.pth\")))\n",
        "    if len(checkpoints) > keep:\n",
        "        for chk in checkpoints[:-keep]:\n",
        "            os.remove(chk)\n",
        "            print(f\"  Cleaned up: {os.path.basename(chk)}\")\n",
        "\n",
        "print(\"Helper functions loaded:\")\n",
        "print(\"  - DKD Loss (Decoupled Knowledge Distillation)\")\n",
        "print(\"  - Standard KD Loss (for comparison)\")\n",
        "print(\"  - CutMix, Mixup augmentations\")\n",
        "print(\"  - Checkpoint utilities\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training function loaded (Version 3: DKD + LR Warmup + Label Smoothing)\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Training Loop (Version 3 - with DKD support)\n",
        "def train_model_v3(model, dataloader, optimizer, scheduler, num_epochs, model_name, \n",
        "                   teacher_model=None, use_dkd=True,\n",
        "                   dkd_alpha=1.0, dkd_beta=8.0, temperature=4.0, label_smoothing=0.1,\n",
        "                   patience=30, grad_clip=1.0, warmup_epochs=5):\n",
        "    \"\"\"\n",
        "    Version 3 Training loop with:\n",
        "    - Decoupled Knowledge Distillation (DKD) loss\n",
        "    - CutMix/Mixup augmentation\n",
        "    - Learning Rate Warmup\n",
        "    - Mixed precision training\n",
        "    - Gradient clipping\n",
        "    - NaN detection and recovery\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. Load Checkpoint\n",
        "    checkpoint = load_checkpoint(model, optimizer, scheduler, model_name)\n",
        "    if checkpoint:\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        history = checkpoint['history']\n",
        "        epochs_no_improve = checkpoint['epochs_no_improve']\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        print(f\"  Resuming from epoch {start_epoch}, Best Acc: {best_acc:.2f}%\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        best_acc = 0.0\n",
        "        history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
        "        epochs_no_improve = 0\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        print(f\"  Starting fresh training...\")\n",
        "\n",
        "    # 2. Setup\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
        "    val_criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Store base LR for warmup\n",
        "    base_lr = optimizer.param_groups[0]['lr']\n",
        "    \n",
        "    if teacher_model:\n",
        "        teacher_model.eval()\n",
        "        for param in teacher_model.parameters():\n",
        "            param.requires_grad = False\n",
        "        loss_type = \"DKD\" if use_dkd else \"Standard KD\"\n",
        "        print(f\"  Using {loss_type} loss with Teacher guidance\")\n",
        "\n",
        "    # 3. Training Loop\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        valid_batches = 0\n",
        "        \n",
        "        # Learning Rate Warmup\n",
        "        if epoch < warmup_epochs:\n",
        "            warmup_lr = base_lr * (epoch + 1) / warmup_epochs\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = warmup_lr\n",
        "        \n",
        "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        \n",
        "        for inputs, labels in loop:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            # Randomly choose Mixup (50%) or CutMix (50%)\n",
        "            use_cutmix = np.random.rand() > 0.5\n",
        "            if use_cutmix:\n",
        "                inputs_aug, labels_a, labels_b, lam = cutmix_data(inputs.clone(), labels, alpha=CUTMIX_ALPHA)\n",
        "            else:\n",
        "                inputs_aug, labels_a, labels_b, lam = mixup_data(inputs, labels, alpha=MIXUP_ALPHA)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                # Student Forward\n",
        "                student_outputs = model(inputs_aug)\n",
        "                \n",
        "                # Loss Calculation\n",
        "                if teacher_model:\n",
        "                    # Teacher Forward (no grad)\n",
        "                    with torch.no_grad():\n",
        "                        teacher_outputs = teacher_model(inputs_aug)\n",
        "                    \n",
        "                    if use_dkd:\n",
        "                        # DKD Loss (Version 3)\n",
        "                        loss = dkd_loss_mixup(\n",
        "                            student_outputs, teacher_outputs, \n",
        "                            labels_a, labels_b, lam,\n",
        "                            alpha=dkd_alpha, beta=dkd_beta, \n",
        "                            temperature=temperature, label_smoothing=label_smoothing\n",
        "                        )\n",
        "                    else:\n",
        "                        # Standard KD Loss (for comparison)\n",
        "                        loss = lam * kd_loss(student_outputs, teacher_outputs, labels_a, temperature, 0.7, label_smoothing) + \\\n",
        "                               (1 - lam) * kd_loss(student_outputs, teacher_outputs, labels_b, temperature, 0.7, label_smoothing)\n",
        "                else:\n",
        "                    # Standard CE with Label Smoothing for Teacher training\n",
        "                    loss = lam * F.cross_entropy(student_outputs, labels_a, label_smoothing=label_smoothing) + \\\n",
        "                           (1 - lam) * F.cross_entropy(student_outputs, labels_b, label_smoothing=label_smoothing)\n",
        "            \n",
        "            # Skip batch if loss is NaN\n",
        "            if torch.isnan(loss):\n",
        "                loop.set_postfix(loss=\"NaN-skip\")\n",
        "                continue\n",
        "            \n",
        "            # Backward\n",
        "            scaler.scale(loss).backward()\n",
        "            \n",
        "            if grad_clip > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                \n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            valid_batches += 1\n",
        "            loop.set_postfix(loss=f\"{loss.item():.3f}\")\n",
        "\n",
        "        # Step Scheduler (only after warmup)\n",
        "        if epoch >= warmup_epochs:\n",
        "            scheduler.step()\n",
        "        \n",
        "        # Validation\n",
        "        train_loss = running_loss / max(valid_batches, 1)\n",
        "        val_acc, val_loss = evaluate_model_with_loss(model, testloader, val_criterion)\n",
        "        \n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_accuracy'].append(val_acc)\n",
        "        \n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | LR: {current_lr:.6f}\")\n",
        "        \n",
        "        # Save Best\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), MODEL_DIR / f\"{model_name}.pth\")\n",
        "            epochs_no_improve = 0\n",
        "            print(f\"  ★ New best model saved! Accuracy: {best_acc:.2f}%\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            \n",
        "        # Checkpointing\n",
        "        if (epoch + 1) % CHECKPOINT_FREQUENCY == 0:\n",
        "            save_checkpoint(model, optimizer, scheduler, epoch, best_acc, history, model_name, epochs_no_improve)\n",
        "            cleanup_old_checkpoints(model_name)\n",
        "            \n",
        "        # Early Stopping\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "            break\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training complete. Best accuracy: {best_acc:.2f}%\")\n",
        "    print(f\"{'='*50}\")\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n",
        "\n",
        "print(\"Training function loaded (Version 3: DKD + LR Warmup + Label Smoothing)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Teacher (EfficientNetV2-L)...\n",
            "Loading Student (EfficientNetV2-S)...\n",
            "Models loaded\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Initialize Models\n",
        "print(\"Loading Teacher (EfficientNetV2-L)...\")\n",
        "teacher_model = efficientnet_v2_l(weights=EfficientNet_V2_L_Weights.IMAGENET1K_V1)\n",
        "teacher_model.classifier[1] = nn.Linear(teacher_model.classifier[1].in_features, NUM_CLASSES)\n",
        "teacher_model = teacher_model.to(device)\n",
        "\n",
        "print(\"Loading Student (EfficientNetV2-S)...\")\n",
        "student_model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
        "student_model.classifier[1] = nn.Linear(student_model.classifier[1].in_features, NUM_CLASSES)\n",
        "student_model = student_model.to(device)\n",
        "\n",
        "print(\"Models loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TEACHER MODEL (Version 3)\n",
            "======================================================================\n",
            "Found existing Teacher v3: outputs\\models\\teacher_v3.pth\n",
            "\n",
            "Teacher v3 Accuracy: 76.02%\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Train/Load Teacher Model (Version 3)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEACHER MODEL (Version 3)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "teacher_path = MODEL_DIR / f\"{TEACHER_NAME}.pth\"\n",
        "\n",
        "# Also check for existing v1/v2 teacher to use as starting point\n",
        "existing_teacher = MODEL_DIR / \"teacher_model.pth\"\n",
        "\n",
        "if teacher_path.exists():\n",
        "    print(f\"Found existing Teacher v3: {teacher_path}\")\n",
        "    teacher_model.load_state_dict(torch.load(teacher_path, map_location=device))\n",
        "elif existing_teacher.exists():\n",
        "    print(f\"Found existing Teacher (v1/v2): {existing_teacher}\")\n",
        "    print(f\"Loading and continuing training for {TEACHER_EPOCHS} epochs...\")\n",
        "    teacher_model.load_state_dict(torch.load(existing_teacher, map_location=device))\n",
        "    \n",
        "    # Continue training with extended epochs\n",
        "    opt_t = optim.AdamW(teacher_model.parameters(), lr=LEARNING_RATE * 0.1, weight_decay=WEIGHT_DECAY)  # Lower LR for fine-tuning\n",
        "    sch_t = optim.lr_scheduler.CosineAnnealingLR(opt_t, T_max=100)  # Additional 100 epochs\n",
        "    \n",
        "    teacher_model, teacher_history = train_model_v3(\n",
        "        teacher_model, trainloader, opt_t, sch_t, \n",
        "        num_epochs=100,  # Additional epochs\n",
        "        model_name=TEACHER_NAME, \n",
        "        teacher_model=None,\n",
        "        warmup_epochs=0  # No warmup for fine-tuning\n",
        "    )\n",
        "else:\n",
        "    print(f\"Training Teacher Model v3 from scratch ({TEACHER_EPOCHS} epochs)...\")\n",
        "    print(\"This may take a while...\")\n",
        "    \n",
        "    # Re-initialize teacher\n",
        "    teacher_model = efficientnet_v2_l(weights=EfficientNet_V2_L_Weights.IMAGENET1K_V1)\n",
        "    teacher_model.classifier[1] = nn.Linear(teacher_model.classifier[1].in_features, NUM_CLASSES)\n",
        "    teacher_model = teacher_model.to(device)\n",
        "    \n",
        "    opt_t = optim.AdamW(teacher_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    sch_t = optim.lr_scheduler.CosineAnnealingLR(opt_t, T_max=TEACHER_EPOCHS - WARMUP_EPOCHS)\n",
        "    \n",
        "    teacher_model, teacher_history = train_model_v3(\n",
        "        teacher_model, trainloader, opt_t, sch_t, \n",
        "        num_epochs=TEACHER_EPOCHS, \n",
        "        model_name=TEACHER_NAME, \n",
        "        teacher_model=None,\n",
        "        warmup_epochs=WARMUP_EPOCHS\n",
        "    )\n",
        "\n",
        "# Evaluate Teacher\n",
        "teacher_model.eval()\n",
        "teacher_accuracy, _ = evaluate_model_with_loss(teacher_model, testloader, nn.CrossEntropyLoss())\n",
        "print(f\"\\nTeacher v3 Accuracy: {teacher_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STUDENT MODEL with Standard KD (Version 4 - Grand Finale)\n",
            "======================================================================\n",
            "Strategy: Best Teacher (v3) + Best KD Method (Standard KD from v2)\n",
            "\n",
            "Starting Standard Knowledge Distillation (v4)...\n",
            "  Using Standard KD (NOT DKD) - proven 98% retention rate\n",
            "  KD Alpha (soft loss weight): 0.7\n",
            "  Temperature: 4.0\n",
            "  Label Smoothing: 0.1\n",
            "  LR Warmup: 5 epochs\n",
            "  Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\n",
            "  Starting fresh training...\n",
            "  Using Standard KD loss with Teacher guidance\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/200: 100%|██████████| 390/390 [01:00<00:00,  6.45it/s, loss=1.654]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200 | Train Loss: 1.7803 | Val Loss: 3.3957 | Val Acc: 23.59% | LR: 0.000200\n",
            "  ★ New best model saved! Accuracy: 23.59%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/200: 100%|██████████| 390/390 [00:55<00:00,  7.03it/s, loss=1.616]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/200 | Train Loss: 1.5911 | Val Loss: 2.6438 | Val Acc: 37.90% | LR: 0.000400\n",
            "  ★ New best model saved! Accuracy: 37.90%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/200: 100%|██████████| 390/390 [00:55<00:00,  7.03it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/200 | Train Loss: 1.5096 | Val Loss: 2.3371 | Val Acc: 44.11% | LR: 0.000600\n",
            "  ★ New best model saved! Accuracy: 44.11%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/200: 100%|██████████| 390/390 [00:55<00:00,  7.01it/s, loss=1.409]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/200 | Train Loss: 1.4841 | Val Loss: 2.3555 | Val Acc: 45.04% | LR: 0.000800\n",
            "  ★ New best model saved! Accuracy: 45.04%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/200: 100%|██████████| 390/390 [00:55<00:00,  7.07it/s, loss=1.488]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/200 | Train Loss: 1.4863 | Val Loss: 2.4051 | Val Acc: 45.84% | LR: 0.001000\n",
            "  ★ New best model saved! Accuracy: 45.84%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/200: 100%|██████████| 390/390 [00:54<00:00,  7.12it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/200 | Train Loss: 1.4368 | Val Loss: 2.2301 | Val Acc: 47.96% | LR: 0.001000\n",
            "  ★ New best model saved! Accuracy: 47.96%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/200: 100%|██████████| 390/390 [00:54<00:00,  7.11it/s, loss=1.493]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/200 | Train Loss: 1.4322 | Val Loss: 2.2842 | Val Acc: 47.38% | LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/200: 100%|██████████| 390/390 [00:55<00:00,  7.08it/s, loss=1.469]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/200 | Train Loss: 1.4203 | Val Loss: 2.0975 | Val Acc: 50.16% | LR: 0.000999\n",
            "  ★ New best model saved! Accuracy: 50.16%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/200: 100%|██████████| 390/390 [00:55<00:00,  7.05it/s, loss=1.419]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/200 | Train Loss: 1.4068 | Val Loss: 2.1822 | Val Acc: 50.23% | LR: 0.000999\n",
            "  ★ New best model saved! Accuracy: 50.23%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/200: 100%|██████████| 390/390 [00:54<00:00,  7.13it/s, loss=1.422]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/200 | Train Loss: 1.4040 | Val Loss: 2.1453 | Val Acc: 50.79% | LR: 0.000998\n",
            "  ★ New best model saved! Accuracy: 50.79%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/200: 100%|██████████| 390/390 [01:17<00:00,  5.04it/s, loss=1.474]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/200 | Train Loss: 1.3955 | Val Loss: 2.2668 | Val Acc: 49.18% | LR: 0.000998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/200: 100%|██████████| 390/390 [00:56<00:00,  6.96it/s, loss=1.435]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/200 | Train Loss: 1.3888 | Val Loss: 2.2636 | Val Acc: 50.98% | LR: 0.000997\n",
            "  ★ New best model saved! Accuracy: 50.98%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/200: 100%|██████████| 390/390 [00:58<00:00,  6.67it/s, loss=1.312]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/200 | Train Loss: 1.3727 | Val Loss: 2.0858 | Val Acc: 52.36% | LR: 0.000996\n",
            "  ★ New best model saved! Accuracy: 52.36%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/200: 100%|██████████| 390/390 [01:08<00:00,  5.71it/s, loss=1.391]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/200 | Train Loss: 1.3743 | Val Loss: 2.0714 | Val Acc: 52.26% | LR: 0.000995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.965]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/200 | Train Loss: 1.3746 | Val Loss: 2.0223 | Val Acc: 53.45% | LR: 0.000994\n",
            "  ★ New best model saved! Accuracy: 53.45%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/200: 100%|██████████| 390/390 [01:14<00:00,  5.25it/s, loss=1.402]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/200 | Train Loss: 1.3541 | Val Loss: 1.9891 | Val Acc: 53.78% | LR: 0.000992\n",
            "  ★ New best model saved! Accuracy: 53.78%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/200: 100%|██████████| 390/390 [01:15<00:00,  5.18it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/200 | Train Loss: 1.3495 | Val Loss: 1.9458 | Val Acc: 54.85% | LR: 0.000991\n",
            "  ★ New best model saved! Accuracy: 54.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/200: 100%|██████████| 390/390 [01:18<00:00,  5.00it/s, loss=1.421]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/200 | Train Loss: 1.3380 | Val Loss: 1.8358 | Val Acc: 55.87% | LR: 0.000989\n",
            "  ★ New best model saved! Accuracy: 55.87%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/200: 100%|██████████| 390/390 [01:10<00:00,  5.57it/s, loss=1.355]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/200 | Train Loss: 1.3273 | Val Loss: 1.9143 | Val Acc: 56.73% | LR: 0.000987\n",
            "  ★ New best model saved! Accuracy: 56.73%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/200: 100%|██████████| 390/390 [01:12<00:00,  5.41it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/200 | Train Loss: 1.3244 | Val Loss: 1.8321 | Val Acc: 57.50% | LR: 0.000985\n",
            "  ★ New best model saved! Accuracy: 57.50%\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v4_standard_kd_epoch20.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/200: 100%|██████████| 390/390 [01:11<00:00,  5.43it/s, loss=1.326]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/200 | Train Loss: 1.3233 | Val Loss: 1.9409 | Val Acc: 56.01% | LR: 0.000983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/200: 100%|██████████| 390/390 [01:12<00:00,  5.40it/s, loss=1.312]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/200 | Train Loss: 1.3185 | Val Loss: 1.8739 | Val Acc: 57.68% | LR: 0.000981\n",
            "  ★ New best model saved! Accuracy: 57.68%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/200: 100%|██████████| 390/390 [01:11<00:00,  5.45it/s, loss=1.273]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/200 | Train Loss: 1.3234 | Val Loss: 1.9005 | Val Acc: 57.14% | LR: 0.000979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/200: 100%|██████████| 390/390 [01:11<00:00,  5.42it/s, loss=1.089]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/200 | Train Loss: 1.3251 | Val Loss: 2.8875 | Val Acc: 55.06% | LR: 0.000977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/200: 100%|██████████| 390/390 [01:12<00:00,  5.38it/s, loss=1.267]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/200 | Train Loss: 1.3255 | Val Loss: 1.9689 | Val Acc: 56.68% | LR: 0.000974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/200: 100%|██████████| 390/390 [01:12<00:00,  5.39it/s, loss=1.623]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/200 | Train Loss: 1.3104 | Val Loss: 1.7865 | Val Acc: 58.51% | LR: 0.000972\n",
            "  ★ New best model saved! Accuracy: 58.51%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/200: 100%|██████████| 390/390 [01:11<00:00,  5.42it/s, loss=1.619]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/200 | Train Loss: 1.2988 | Val Loss: 1.8533 | Val Acc: 59.26% | LR: 0.000969\n",
            "  ★ New best model saved! Accuracy: 59.26%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/200: 100%|██████████| 390/390 [01:12<00:00,  5.36it/s, loss=1.361]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/200 | Train Loss: 1.2915 | Val Loss: 1.7341 | Val Acc: 59.06% | LR: 0.000966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/200: 100%|██████████| 390/390 [01:12<00:00,  5.39it/s, loss=1.187]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/200 | Train Loss: 1.2808 | Val Loss: 1.8973 | Val Acc: 59.14% | LR: 0.000963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/200: 100%|██████████| 390/390 [01:12<00:00,  5.39it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/200 | Train Loss: 1.2769 | Val Loss: 1.7997 | Val Acc: 58.98% | LR: 0.000960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/200: 100%|██████████| 390/390 [01:12<00:00,  5.40it/s, loss=1.144]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31/200 | Train Loss: 1.2898 | Val Loss: 1.7722 | Val Acc: 57.87% | LR: 0.000957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/200: 100%|██████████| 390/390 [01:11<00:00,  5.47it/s, loss=1.230]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32/200 | Train Loss: 1.2694 | Val Loss: 1.7988 | Val Acc: 58.55% | LR: 0.000953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/200: 100%|██████████| 390/390 [01:12<00:00,  5.39it/s, loss=1.359]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33/200 | Train Loss: 1.2661 | Val Loss: 1.8971 | Val Acc: 58.31% | LR: 0.000950\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/200: 100%|██████████| 390/390 [01:11<00:00,  5.43it/s, loss=1.069]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34/200 | Train Loss: 1.2750 | Val Loss: 1.7337 | Val Acc: 60.40% | LR: 0.000946\n",
            "  ★ New best model saved! Accuracy: 60.40%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/200: 100%|██████████| 390/390 [01:12<00:00,  5.39it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35/200 | Train Loss: 1.2752 | Val Loss: 1.8935 | Val Acc: 58.95% | LR: 0.000943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/200: 100%|██████████| 390/390 [01:12<00:00,  5.39it/s, loss=1.291]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36/200 | Train Loss: 1.2718 | Val Loss: 1.8039 | Val Acc: 60.22% | LR: 0.000939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/200: 100%|██████████| 390/390 [01:12<00:00,  5.39it/s, loss=1.294]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37/200 | Train Loss: 1.2802 | Val Loss: 1.7650 | Val Acc: 59.41% | LR: 0.000935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/200: 100%|██████████| 390/390 [01:12<00:00,  5.37it/s, loss=1.398]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38/200 | Train Loss: 1.2727 | Val Loss: 1.8156 | Val Acc: 60.51% | LR: 0.000931\n",
            "  ★ New best model saved! Accuracy: 60.51%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/200: 100%|██████████| 390/390 [01:11<00:00,  5.43it/s, loss=1.363]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39/200 | Train Loss: 1.2602 | Val Loss: 1.9566 | Val Acc: 58.90% | LR: 0.000927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/200: 100%|██████████| 390/390 [01:12<00:00,  5.36it/s, loss=1.242]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40/200 | Train Loss: 1.2641 | Val Loss: 2.0325 | Val Acc: 60.37% | LR: 0.000923\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v4_standard_kd_epoch40.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/200: 100%|██████████| 390/390 [01:12<00:00,  5.40it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41/200 | Train Loss: 1.2652 | Val Loss: 1.7359 | Val Acc: 60.79% | LR: 0.000918\n",
            "  ★ New best model saved! Accuracy: 60.79%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=1.143]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42/200 | Train Loss: 1.2722 | Val Loss: 1.6732 | Val Acc: 62.01% | LR: 0.000914\n",
            "  ★ New best model saved! Accuracy: 62.01%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/200: 100%|██████████| 390/390 [01:11<00:00,  5.44it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43/200 | Train Loss: 1.2657 | Val Loss: 1.7267 | Val Acc: 61.97% | LR: 0.000909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/200: 100%|██████████| 390/390 [01:08<00:00,  5.66it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44/200 | Train Loss: 1.2407 | Val Loss: 1.6042 | Val Acc: 62.75% | LR: 0.000905\n",
            "  ★ New best model saved! Accuracy: 62.75%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/200: 100%|██████████| 390/390 [01:10<00:00,  5.54it/s, loss=0.840]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45/200 | Train Loss: 1.2412 | Val Loss: 1.6259 | Val Acc: 62.53% | LR: 0.000900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/200: 100%|██████████| 390/390 [01:14<00:00,  5.24it/s, loss=1.198]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46/200 | Train Loss: 1.2331 | Val Loss: 1.6687 | Val Acc: 61.40% | LR: 0.000895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47/200 | Train Loss: 1.2463 | Val Loss: 1.8568 | Val Acc: 61.43% | LR: 0.000890\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=1.301]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48/200 | Train Loss: 1.2498 | Val Loss: 1.9589 | Val Acc: 61.43% | LR: 0.000885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=1.293]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49/200 | Train Loss: 1.2563 | Val Loss: 1.8714 | Val Acc: 61.89% | LR: 0.000880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50/200: 100%|██████████| 390/390 [01:14<00:00,  5.25it/s, loss=1.375]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50/200 | Train Loss: 1.2404 | Val Loss: 1.9250 | Val Acc: 62.26% | LR: 0.000874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 51/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=1.160]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51/200 | Train Loss: 1.2298 | Val Loss: 1.8101 | Val Acc: 61.71% | LR: 0.000869\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 52/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=1.202]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52/200 | Train Loss: 1.2241 | Val Loss: 1.5780 | Val Acc: 63.87% | LR: 0.000863\n",
            "  ★ New best model saved! Accuracy: 63.87%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 53/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=1.356]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53/200 | Train Loss: 1.2271 | Val Loss: 1.7075 | Val Acc: 62.54% | LR: 0.000858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 54/200: 100%|██████████| 390/390 [01:14<00:00,  5.21it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54/200 | Train Loss: 1.2333 | Val Loss: 1.8102 | Val Acc: 63.19% | LR: 0.000852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 55/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=1.684]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55/200 | Train Loss: 1.2208 | Val Loss: 1.6182 | Val Acc: 63.19% | LR: 0.000846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 56/200: 100%|██████████| 390/390 [01:10<00:00,  5.57it/s, loss=1.306]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56/200 | Train Loss: 1.2357 | Val Loss: 1.6686 | Val Acc: 62.62% | LR: 0.000841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 57/200: 100%|██████████| 390/390 [01:09<00:00,  5.57it/s, loss=1.263]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57/200 | Train Loss: 1.2110 | Val Loss: 1.6887 | Val Acc: 63.16% | LR: 0.000835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 58/200: 100%|██████████| 390/390 [01:09<00:00,  5.58it/s, loss=1.022]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58/200 | Train Loss: 1.2102 | Val Loss: 1.6950 | Val Acc: 63.16% | LR: 0.000829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 59/200: 100%|██████████| 390/390 [01:09<00:00,  5.64it/s, loss=1.272]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59/200 | Train Loss: 1.2316 | Val Loss: 1.9777 | Val Acc: 62.77% | LR: 0.000822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 60/200: 100%|██████████| 390/390 [01:09<00:00,  5.59it/s, loss=1.067]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60/200 | Train Loss: 1.2226 | Val Loss: 1.5789 | Val Acc: 63.78% | LR: 0.000816\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v4_standard_kd_epoch60.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 61/200: 100%|██████████| 390/390 [01:09<00:00,  5.60it/s, loss=1.317]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 61/200 | Train Loss: 1.2151 | Val Loss: 1.5857 | Val Acc: 63.78% | LR: 0.000810\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 62/200: 100%|██████████| 390/390 [01:09<00:00,  5.61it/s, loss=1.441]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 62/200 | Train Loss: 1.2208 | Val Loss: 1.7051 | Val Acc: 63.09% | LR: 0.000804\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 63/200: 100%|██████████| 390/390 [01:09<00:00,  5.61it/s, loss=1.049]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 63/200 | Train Loss: 1.2090 | Val Loss: 1.6047 | Val Acc: 63.90% | LR: 0.000797\n",
            "  ★ New best model saved! Accuracy: 63.90%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 64/200: 100%|██████████| 390/390 [01:10<00:00,  5.56it/s, loss=1.245]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 64/200 | Train Loss: 1.2204 | Val Loss: 2.0664 | Val Acc: 61.41% | LR: 0.000791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 65/200: 100%|██████████| 390/390 [01:09<00:00,  5.59it/s, loss=1.023]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 65/200 | Train Loss: 1.2289 | Val Loss: 1.7653 | Val Acc: 63.92% | LR: 0.000784\n",
            "  ★ New best model saved! Accuracy: 63.92%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 66/200: 100%|██████████| 390/390 [01:09<00:00,  5.59it/s, loss=1.275]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66/200 | Train Loss: 1.2095 | Val Loss: 1.6016 | Val Acc: 64.32% | LR: 0.000777\n",
            "  ★ New best model saved! Accuracy: 64.32%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 67/200: 100%|██████████| 390/390 [01:09<00:00,  5.63it/s, loss=1.365]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 67/200 | Train Loss: 1.2123 | Val Loss: 1.6652 | Val Acc: 63.29% | LR: 0.000771\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 68/200: 100%|██████████| 390/390 [01:09<00:00,  5.59it/s, loss=1.282]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 68/200 | Train Loss: 1.1965 | Val Loss: 1.5824 | Val Acc: 63.92% | LR: 0.000764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 69/200: 100%|██████████| 390/390 [01:09<00:00,  5.58it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 69/200 | Train Loss: 1.2144 | Val Loss: 1.4914 | Val Acc: 65.48% | LR: 0.000757\n",
            "  ★ New best model saved! Accuracy: 65.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 70/200: 100%|██████████| 390/390 [01:10<00:00,  5.56it/s, loss=1.194]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70/200 | Train Loss: 1.2000 | Val Loss: 1.6874 | Val Acc: 63.37% | LR: 0.000750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 71/200: 100%|██████████| 390/390 [01:09<00:00,  5.60it/s, loss=1.348]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 71/200 | Train Loss: 1.1814 | Val Loss: 1.6966 | Val Acc: 63.64% | LR: 0.000743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 72/200: 100%|██████████| 390/390 [01:11<00:00,  5.47it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 72/200 | Train Loss: 1.1842 | Val Loss: 1.5837 | Val Acc: 64.15% | LR: 0.000736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 73/200: 100%|██████████| 390/390 [01:11<00:00,  5.46it/s, loss=0.948]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 73/200 | Train Loss: 1.2046 | Val Loss: 1.5159 | Val Acc: 65.59% | LR: 0.000729\n",
            "  ★ New best model saved! Accuracy: 65.59%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 74/200: 100%|██████████| 390/390 [01:12<00:00,  5.40it/s, loss=0.736]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 74/200 | Train Loss: 1.1973 | Val Loss: 1.5696 | Val Acc: 66.22% | LR: 0.000722\n",
            "  ★ New best model saved! Accuracy: 66.22%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 75/200: 100%|██████████| 390/390 [01:11<00:00,  5.44it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 75/200 | Train Loss: 1.2040 | Val Loss: 1.5205 | Val Acc: 65.13% | LR: 0.000714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 76/200: 100%|██████████| 390/390 [01:11<00:00,  5.44it/s, loss=1.328]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 76/200 | Train Loss: 1.1993 | Val Loss: 1.5431 | Val Acc: 65.04% | LR: 0.000707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 77/200: 100%|██████████| 390/390 [01:13<00:00,  5.34it/s, loss=1.180]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 77/200 | Train Loss: 1.1999 | Val Loss: 1.5776 | Val Acc: 65.58% | LR: 0.000700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 78/200: 100%|██████████| 390/390 [01:11<00:00,  5.45it/s, loss=1.207]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 78/200 | Train Loss: 1.1938 | Val Loss: 1.6017 | Val Acc: 63.98% | LR: 0.000692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 79/200: 100%|██████████| 390/390 [01:11<00:00,  5.45it/s, loss=1.237]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 79/200 | Train Loss: 1.1817 | Val Loss: 1.5861 | Val Acc: 64.82% | LR: 0.000685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 80/200: 100%|██████████| 390/390 [01:12<00:00,  5.35it/s, loss=1.332]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 80/200 | Train Loss: 1.1812 | Val Loss: 1.5419 | Val Acc: 65.23% | LR: 0.000677\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v4_standard_kd_epoch80.pth\n",
            "  Cleaned up: student_v4_standard_kd_epoch20.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 81/200: 100%|██████████| 390/390 [01:09<00:00,  5.59it/s, loss=1.246]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 81/200 | Train Loss: 1.1830 | Val Loss: 1.4961 | Val Acc: 66.24% | LR: 0.000670\n",
            "  ★ New best model saved! Accuracy: 66.24%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 82/200: 100%|██████████| 390/390 [01:08<00:00,  5.67it/s, loss=1.401]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 82/200 | Train Loss: 1.1753 | Val Loss: 1.6072 | Val Acc: 64.34% | LR: 0.000662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 83/200: 100%|██████████| 390/390 [01:09<00:00,  5.61it/s, loss=1.382]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 83/200 | Train Loss: 1.1810 | Val Loss: 1.5297 | Val Acc: 65.73% | LR: 0.000655\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 84/200: 100%|██████████| 390/390 [01:10<00:00,  5.54it/s, loss=1.181]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 84/200 | Train Loss: 1.1947 | Val Loss: 1.5218 | Val Acc: 65.53% | LR: 0.000647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 85/200: 100%|██████████| 390/390 [01:09<00:00,  5.64it/s, loss=0.837]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 85/200 | Train Loss: 1.1788 | Val Loss: 1.4808 | Val Acc: 66.79% | LR: 0.000639\n",
            "  ★ New best model saved! Accuracy: 66.79%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 86/200: 100%|██████████| 390/390 [01:09<00:00,  5.65it/s, loss=1.248]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 86/200 | Train Loss: 1.1779 | Val Loss: 1.5627 | Val Acc: 65.36% | LR: 0.000631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 87/200: 100%|██████████| 390/390 [01:09<00:00,  5.59it/s, loss=1.165]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 87/200 | Train Loss: 1.1807 | Val Loss: 1.5660 | Val Acc: 65.32% | LR: 0.000624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 88/200: 100%|██████████| 390/390 [01:09<00:00,  5.64it/s, loss=0.906]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 88/200 | Train Loss: 1.1463 | Val Loss: 1.4615 | Val Acc: 67.09% | LR: 0.000616\n",
            "  ★ New best model saved! Accuracy: 67.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 89/200: 100%|██████████| 390/390 [01:10<00:00,  5.56it/s, loss=1.240]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 89/200 | Train Loss: 1.1771 | Val Loss: 1.5058 | Val Acc: 66.43% | LR: 0.000608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 90/200: 100%|██████████| 390/390 [01:09<00:00,  5.62it/s, loss=1.281]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 90/200 | Train Loss: 1.1782 | Val Loss: 1.4790 | Val Acc: 66.77% | LR: 0.000600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 91/200: 100%|██████████| 390/390 [01:09<00:00,  5.63it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 91/200 | Train Loss: 1.1799 | Val Loss: 1.4966 | Val Acc: 66.55% | LR: 0.000592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 92/200: 100%|██████████| 390/390 [01:10<00:00,  5.56it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 92/200 | Train Loss: 1.1521 | Val Loss: 1.4894 | Val Acc: 67.13% | LR: 0.000584\n",
            "  ★ New best model saved! Accuracy: 67.13%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 93/200: 100%|██████████| 390/390 [01:09<00:00,  5.57it/s, loss=1.291]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 93/200 | Train Loss: 1.1745 | Val Loss: 1.4769 | Val Acc: 67.06% | LR: 0.000576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 94/200: 100%|██████████| 390/390 [01:09<00:00,  5.59it/s, loss=0.830]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 94/200 | Train Loss: 1.1654 | Val Loss: 1.4754 | Val Acc: 66.72% | LR: 0.000568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 95/200: 100%|██████████| 390/390 [01:09<00:00,  5.59it/s, loss=0.983]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 95/200 | Train Loss: 1.1581 | Val Loss: 1.4884 | Val Acc: 66.61% | LR: 0.000560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 96/200: 100%|██████████| 390/390 [01:09<00:00,  5.62it/s, loss=1.128]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 96/200 | Train Loss: 1.1453 | Val Loss: 1.3943 | Val Acc: 67.87% | LR: 0.000552\n",
            "  ★ New best model saved! Accuracy: 67.87%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 97/200: 100%|██████████| 390/390 [01:09<00:00,  5.63it/s, loss=1.083]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 97/200 | Train Loss: 1.1686 | Val Loss: 1.4881 | Val Acc: 66.59% | LR: 0.000544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 98/200: 100%|██████████| 390/390 [01:09<00:00,  5.62it/s, loss=1.115]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 98/200 | Train Loss: 1.1646 | Val Loss: 1.4558 | Val Acc: 67.67% | LR: 0.000536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 99/200: 100%|██████████| 390/390 [01:09<00:00,  5.63it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 99/200 | Train Loss: 1.1591 | Val Loss: 1.4946 | Val Acc: 66.89% | LR: 0.000528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 100/200: 100%|██████████| 390/390 [01:09<00:00,  5.62it/s, loss=1.691]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100/200 | Train Loss: 1.1559 | Val Loss: 1.4987 | Val Acc: 67.07% | LR: 0.000520\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v4_standard_kd_epoch100.pth\n",
            "  Cleaned up: student_v4_standard_kd_epoch100.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 101/200: 100%|██████████| 390/390 [01:18<00:00,  5.00it/s, loss=1.191]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 101/200 | Train Loss: 1.1660 | Val Loss: 1.4481 | Val Acc: 67.21% | LR: 0.000512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 102/200: 100%|██████████| 390/390 [01:09<00:00,  5.60it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 102/200 | Train Loss: 1.1451 | Val Loss: 1.4669 | Val Acc: 67.39% | LR: 0.000504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 103/200: 100%|██████████| 390/390 [01:11<00:00,  5.48it/s, loss=1.340]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 103/200 | Train Loss: 1.1346 | Val Loss: 1.4953 | Val Acc: 66.97% | LR: 0.000496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 104/200: 100%|██████████| 390/390 [01:11<00:00,  5.46it/s, loss=1.201]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 104/200 | Train Loss: 1.1351 | Val Loss: 1.4522 | Val Acc: 67.61% | LR: 0.000488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 105/200: 100%|██████████| 390/390 [01:12<00:00,  5.40it/s, loss=1.248]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 105/200 | Train Loss: 1.1417 | Val Loss: 1.4771 | Val Acc: 67.28% | LR: 0.000480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 106/200: 100%|██████████| 390/390 [01:11<00:00,  5.45it/s, loss=1.249]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 106/200 | Train Loss: 1.1482 | Val Loss: 1.4142 | Val Acc: 68.71% | LR: 0.000472\n",
            "  ★ New best model saved! Accuracy: 68.71%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 107/200: 100%|██████████| 390/390 [01:11<00:00,  5.47it/s, loss=1.101]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 107/200 | Train Loss: 1.1362 | Val Loss: 1.3789 | Val Acc: 68.09% | LR: 0.000464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 108/200: 100%|██████████| 390/390 [01:11<00:00,  5.46it/s, loss=1.217]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 108/200 | Train Loss: 1.1444 | Val Loss: 1.4862 | Val Acc: 68.17% | LR: 0.000456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 109/200: 100%|██████████| 390/390 [01:11<00:00,  5.42it/s, loss=0.823]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 109/200 | Train Loss: 1.1421 | Val Loss: 1.4082 | Val Acc: 68.10% | LR: 0.000448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 110/200: 100%|██████████| 390/390 [01:12<00:00,  5.39it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 110/200 | Train Loss: 1.1251 | Val Loss: 1.3391 | Val Acc: 69.20% | LR: 0.000440\n",
            "  ★ New best model saved! Accuracy: 69.20%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 111/200: 100%|██████████| 390/390 [01:12<00:00,  5.39it/s, loss=1.160]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 111/200 | Train Loss: 1.1323 | Val Loss: 1.4599 | Val Acc: 68.84% | LR: 0.000432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 112/200: 100%|██████████| 390/390 [01:11<00:00,  5.43it/s, loss=1.459]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 112/200 | Train Loss: 1.1389 | Val Loss: 1.4193 | Val Acc: 68.71% | LR: 0.000424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 113/200: 100%|██████████| 390/390 [01:12<00:00,  5.42it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 113/200 | Train Loss: 1.1357 | Val Loss: 1.4578 | Val Acc: 68.60% | LR: 0.000416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 114/200: 100%|██████████| 390/390 [01:11<00:00,  5.47it/s, loss=0.997]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 114/200 | Train Loss: 1.1256 | Val Loss: 1.5008 | Val Acc: 69.34% | LR: 0.000408\n",
            "  ★ New best model saved! Accuracy: 69.34%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 115/200: 100%|██████████| 390/390 [01:11<00:00,  5.43it/s, loss=1.165]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 115/200 | Train Loss: 1.1203 | Val Loss: 1.4519 | Val Acc: 68.64% | LR: 0.000400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 116/200: 100%|██████████| 390/390 [01:12<00:00,  5.40it/s, loss=0.718]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 116/200 | Train Loss: 1.1265 | Val Loss: 1.3881 | Val Acc: 69.19% | LR: 0.000392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 117/200: 100%|██████████| 390/390 [01:11<00:00,  5.43it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 117/200 | Train Loss: 1.1172 | Val Loss: 1.3954 | Val Acc: 69.62% | LR: 0.000384\n",
            "  ★ New best model saved! Accuracy: 69.62%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 118/200: 100%|██████████| 390/390 [01:12<00:00,  5.39it/s, loss=0.977]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 118/200 | Train Loss: 1.1196 | Val Loss: 1.4178 | Val Acc: 69.13% | LR: 0.000376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 119/200: 100%|██████████| 390/390 [01:11<00:00,  5.49it/s, loss=1.121]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 119/200 | Train Loss: 1.1010 | Val Loss: 1.3605 | Val Acc: 69.74% | LR: 0.000369\n",
            "  ★ New best model saved! Accuracy: 69.74%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 120/200: 100%|██████████| 390/390 [01:12<00:00,  5.37it/s, loss=1.279]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 120/200 | Train Loss: 1.0996 | Val Loss: 1.3870 | Val Acc: 69.42% | LR: 0.000361\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v4_standard_kd_epoch120.pth\n",
            "  Cleaned up: student_v4_standard_kd_epoch120.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 121/200: 100%|██████████| 390/390 [01:11<00:00,  5.49it/s, loss=0.759]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 121/200 | Train Loss: 1.1136 | Val Loss: 1.3964 | Val Acc: 68.91% | LR: 0.000353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 122/200: 100%|██████████| 390/390 [01:10<00:00,  5.51it/s, loss=1.245]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 122/200 | Train Loss: 1.0994 | Val Loss: 1.4180 | Val Acc: 68.85% | LR: 0.000345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 123/200: 100%|██████████| 390/390 [01:16<00:00,  5.13it/s, loss=1.164]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 123/200 | Train Loss: 1.1121 | Val Loss: 1.4779 | Val Acc: 68.27% | LR: 0.000338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 124/200: 100%|██████████| 390/390 [00:59<00:00,  6.60it/s, loss=1.043]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 124/200 | Train Loss: 1.1103 | Val Loss: 1.3629 | Val Acc: 69.60% | LR: 0.000330\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 125/200: 100%|██████████| 390/390 [01:10<00:00,  5.51it/s, loss=1.119]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 125/200 | Train Loss: 1.1159 | Val Loss: 1.3614 | Val Acc: 69.34% | LR: 0.000323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 126/200: 100%|██████████| 390/390 [01:11<00:00,  5.42it/s, loss=1.229]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 126/200 | Train Loss: 1.0980 | Val Loss: 1.4870 | Val Acc: 69.47% | LR: 0.000315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 127/200: 100%|██████████| 390/390 [01:26<00:00,  4.53it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 127/200 | Train Loss: 1.1117 | Val Loss: 1.3549 | Val Acc: 70.31% | LR: 0.000308\n",
            "  ★ New best model saved! Accuracy: 70.31%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 128/200: 100%|██████████| 390/390 [01:21<00:00,  4.79it/s, loss=1.116]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 128/200 | Train Loss: 1.1237 | Val Loss: 1.3314 | Val Acc: 70.23% | LR: 0.000300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 129/200: 100%|██████████| 390/390 [01:23<00:00,  4.67it/s, loss=1.154]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 129/200 | Train Loss: 1.1266 | Val Loss: 1.5209 | Val Acc: 69.31% | LR: 0.000293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 130/200: 100%|██████████| 390/390 [01:24<00:00,  4.61it/s, loss=1.020]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 130/200 | Train Loss: 1.1009 | Val Loss: 1.3444 | Val Acc: 70.43% | LR: 0.000286\n",
            "  ★ New best model saved! Accuracy: 70.43%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 131/200: 100%|██████████| 390/390 [01:23<00:00,  4.66it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 131/200 | Train Loss: 1.1047 | Val Loss: 1.3689 | Val Acc: 70.12% | LR: 0.000278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 132/200: 100%|██████████| 390/390 [00:59<00:00,  6.54it/s, loss=0.985]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 132/200 | Train Loss: 1.1059 | Val Loss: 1.5019 | Val Acc: 69.74% | LR: 0.000271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 133/200: 100%|██████████| 390/390 [01:12<00:00,  5.38it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 133/200 | Train Loss: 1.0826 | Val Loss: 1.2774 | Val Acc: 71.30% | LR: 0.000264\n",
            "  ★ New best model saved! Accuracy: 71.30%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 134/200: 100%|██████████| 390/390 [01:14<00:00,  5.21it/s, loss=1.218]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 134/200 | Train Loss: 1.1026 | Val Loss: 1.3211 | Val Acc: 71.06% | LR: 0.000257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 135/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=1.174]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 135/200 | Train Loss: 1.0897 | Val Loss: 1.2844 | Val Acc: 71.12% | LR: 0.000250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 136/200: 100%|██████████| 390/390 [01:14<00:00,  5.20it/s, loss=0.895]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 136/200 | Train Loss: 1.1038 | Val Loss: 1.3196 | Val Acc: 71.16% | LR: 0.000243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 137/200: 100%|██████████| 390/390 [01:14<00:00,  5.27it/s, loss=1.062]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 137/200 | Train Loss: 1.1002 | Val Loss: 1.3246 | Val Acc: 70.91% | LR: 0.000236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 138/200: 100%|██████████| 390/390 [01:12<00:00,  5.38it/s, loss=1.134]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 138/200 | Train Loss: 1.0859 | Val Loss: 1.3609 | Val Acc: 70.88% | LR: 0.000229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 139/200: 100%|██████████| 390/390 [01:21<00:00,  4.77it/s, loss=1.219]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 139/200 | Train Loss: 1.0806 | Val Loss: 1.3298 | Val Acc: 70.75% | LR: 0.000223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 140/200: 100%|██████████| 390/390 [01:09<00:00,  5.63it/s, loss=1.078]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 140/200 | Train Loss: 1.0839 | Val Loss: 1.2421 | Val Acc: 71.52% | LR: 0.000216\n",
            "  ★ New best model saved! Accuracy: 71.52%\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v4_standard_kd_epoch140.pth\n",
            "  Cleaned up: student_v4_standard_kd_epoch140.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 141/200: 100%|██████████| 390/390 [01:08<00:00,  5.71it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 141/200 | Train Loss: 1.0974 | Val Loss: 1.2685 | Val Acc: 71.88% | LR: 0.000209\n",
            "  ★ New best model saved! Accuracy: 71.88%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 142/200: 100%|██████████| 390/390 [01:08<00:00,  5.68it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 142/200 | Train Loss: 1.0787 | Val Loss: 1.3336 | Val Acc: 71.39% | LR: 0.000203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 143/200: 100%|██████████| 390/390 [01:09<00:00,  5.59it/s, loss=0.931]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 143/200 | Train Loss: 1.0803 | Val Loss: 1.2983 | Val Acc: 72.01% | LR: 0.000196\n",
            "  ★ New best model saved! Accuracy: 72.01%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 144/200: 100%|██████████| 390/390 [01:09<00:00,  5.62it/s, loss=1.127]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 144/200 | Train Loss: 1.0798 | Val Loss: 1.2960 | Val Acc: 72.27% | LR: 0.000190\n",
            "  ★ New best model saved! Accuracy: 72.27%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 145/200: 100%|██████████| 390/390 [01:08<00:00,  5.66it/s, loss=1.472]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 145/200 | Train Loss: 1.0760 | Val Loss: 1.2869 | Val Acc: 71.80% | LR: 0.000184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 146/200: 100%|██████████| 390/390 [01:10<00:00,  5.54it/s, loss=0.897]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 146/200 | Train Loss: 1.0858 | Val Loss: 1.2996 | Val Acc: 71.31% | LR: 0.000178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 147/200: 100%|██████████| 390/390 [01:09<00:00,  5.65it/s, loss=0.985]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 147/200 | Train Loss: 1.0778 | Val Loss: 1.2695 | Val Acc: 72.13% | LR: 0.000171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 148/200: 100%|██████████| 390/390 [01:09<00:00,  5.62it/s, loss=0.763]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 148/200 | Train Loss: 1.0699 | Val Loss: 1.2605 | Val Acc: 72.29% | LR: 0.000165\n",
            "  ★ New best model saved! Accuracy: 72.29%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 149/200: 100%|██████████| 390/390 [01:09<00:00,  5.59it/s, loss=0.950]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 149/200 | Train Loss: 1.0754 | Val Loss: 1.2794 | Val Acc: 72.07% | LR: 0.000159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 150/200: 100%|██████████| 390/390 [01:10<00:00,  5.54it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 150/200 | Train Loss: 1.0613 | Val Loss: 1.2878 | Val Acc: 72.16% | LR: 0.000154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 151/200: 100%|██████████| 390/390 [01:09<00:00,  5.65it/s, loss=1.213]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 151/200 | Train Loss: 1.0672 | Val Loss: 1.3635 | Val Acc: 71.71% | LR: 0.000148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 152/200: 100%|██████████| 390/390 [01:07<00:00,  5.75it/s, loss=1.000]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 152/200 | Train Loss: 1.0533 | Val Loss: 1.2743 | Val Acc: 72.84% | LR: 0.000142\n",
            "  ★ New best model saved! Accuracy: 72.84%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 153/200: 100%|██████████| 390/390 [00:55<00:00,  6.98it/s, loss=1.017]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 153/200 | Train Loss: 1.0612 | Val Loss: 1.2884 | Val Acc: 72.77% | LR: 0.000137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 154/200: 100%|██████████| 390/390 [00:55<00:00,  7.02it/s, loss=1.184]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 154/200 | Train Loss: 1.0912 | Val Loss: 1.2973 | Val Acc: 72.39% | LR: 0.000131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 155/200: 100%|██████████| 390/390 [00:56<00:00,  6.94it/s, loss=0.705]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 155/200 | Train Loss: 1.0668 | Val Loss: 1.2632 | Val Acc: 72.20% | LR: 0.000126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 156/200: 100%|██████████| 390/390 [00:55<00:00,  7.00it/s, loss=0.695]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 156/200 | Train Loss: 1.0770 | Val Loss: 1.3488 | Val Acc: 71.41% | LR: 0.000120\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 157/200: 100%|██████████| 390/390 [00:55<00:00,  6.97it/s, loss=1.210]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 157/200 | Train Loss: 1.0581 | Val Loss: 1.2720 | Val Acc: 72.48% | LR: 0.000115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 158/200: 100%|██████████| 390/390 [00:56<00:00,  6.96it/s, loss=1.140]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 158/200 | Train Loss: 1.0676 | Val Loss: 1.3179 | Val Acc: 72.19% | LR: 0.000110\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 159/200: 100%|██████████| 390/390 [00:55<00:00,  7.02it/s, loss=1.112]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 159/200 | Train Loss: 1.0423 | Val Loss: 1.2936 | Val Acc: 72.65% | LR: 0.000105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 160/200: 100%|██████████| 390/390 [00:55<00:00,  6.98it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 160/200 | Train Loss: 1.0524 | Val Loss: 1.2694 | Val Acc: 72.63% | LR: 0.000100\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v4_standard_kd_epoch160.pth\n",
            "  Cleaned up: student_v4_standard_kd_epoch160.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 161/200: 100%|██████████| 390/390 [00:55<00:00,  7.03it/s, loss=0.670]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 161/200 | Train Loss: 1.0475 | Val Loss: 1.2382 | Val Acc: 73.21% | LR: 0.000095\n",
            "  ★ New best model saved! Accuracy: 73.21%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 162/200: 100%|██████████| 390/390 [01:10<00:00,  5.51it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 162/200 | Train Loss: 1.0495 | Val Loss: 1.2969 | Val Acc: 72.56% | LR: 0.000091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 163/200: 100%|██████████| 390/390 [01:09<00:00,  5.60it/s, loss=0.726]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 163/200 | Train Loss: 1.0526 | Val Loss: 1.2363 | Val Acc: 72.93% | LR: 0.000086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 164/200: 100%|██████████| 390/390 [01:10<00:00,  5.56it/s, loss=1.725]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 164/200 | Train Loss: 1.0658 | Val Loss: 1.3001 | Val Acc: 73.00% | LR: 0.000082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 165/200: 100%|██████████| 390/390 [01:08<00:00,  5.65it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 165/200 | Train Loss: 1.0680 | Val Loss: 1.3472 | Val Acc: 72.82% | LR: 0.000077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 166/200: 100%|██████████| 390/390 [01:08<00:00,  5.69it/s, loss=0.911]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 166/200 | Train Loss: 1.0297 | Val Loss: 1.2655 | Val Acc: 72.62% | LR: 0.000073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 167/200: 100%|██████████| 390/390 [01:09<00:00,  5.57it/s, loss=0.622]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 167/200 | Train Loss: 1.0628 | Val Loss: 1.2861 | Val Acc: 72.65% | LR: 0.000069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 168/200: 100%|██████████| 390/390 [01:09<00:00,  5.64it/s, loss=0.792]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 168/200 | Train Loss: 1.0340 | Val Loss: 1.2566 | Val Acc: 73.11% | LR: 0.000065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 169/200: 100%|██████████| 390/390 [01:09<00:00,  5.63it/s, loss=0.907]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 169/200 | Train Loss: 1.0268 | Val Loss: 1.2431 | Val Acc: 73.30% | LR: 0.000061\n",
            "  ★ New best model saved! Accuracy: 73.30%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 170/200: 100%|██████████| 390/390 [01:08<00:00,  5.67it/s, loss=1.082]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 170/200 | Train Loss: 1.0342 | Val Loss: 1.2345 | Val Acc: 73.40% | LR: 0.000057\n",
            "  ★ New best model saved! Accuracy: 73.40%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 171/200: 100%|██████████| 390/390 [01:09<00:00,  5.61it/s, loss=0.976]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 171/200 | Train Loss: 1.0445 | Val Loss: 1.2557 | Val Acc: 72.98% | LR: 0.000054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 172/200: 100%|██████████| 390/390 [01:09<00:00,  5.60it/s, loss=0.932]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 172/200 | Train Loss: 1.0440 | Val Loss: 1.2748 | Val Acc: 73.30% | LR: 0.000050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 173/200: 100%|██████████| 390/390 [01:09<00:00,  5.59it/s, loss=0.770]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 173/200 | Train Loss: 1.0282 | Val Loss: 1.2176 | Val Acc: 73.43% | LR: 0.000047\n",
            "  ★ New best model saved! Accuracy: 73.43%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 174/200: 100%|██████████| 390/390 [01:10<00:00,  5.56it/s, loss=0.677]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 174/200 | Train Loss: 1.0169 | Val Loss: 1.2114 | Val Acc: 73.56% | LR: 0.000043\n",
            "  ★ New best model saved! Accuracy: 73.56%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 175/200: 100%|██████████| 390/390 [01:09<00:00,  5.64it/s, loss=1.177]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 175/200 | Train Loss: 1.0339 | Val Loss: 1.2764 | Val Acc: 73.29% | LR: 0.000040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 176/200: 100%|██████████| 390/390 [01:09<00:00,  5.62it/s, loss=1.174]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 176/200 | Train Loss: 1.0244 | Val Loss: 1.2123 | Val Acc: 73.86% | LR: 0.000037\n",
            "  ★ New best model saved! Accuracy: 73.86%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 177/200: 100%|██████████| 390/390 [01:09<00:00,  5.62it/s, loss=1.179]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 177/200 | Train Loss: 1.0544 | Val Loss: 1.2652 | Val Acc: 73.44% | LR: 0.000034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 178/200: 100%|██████████| 390/390 [01:09<00:00,  5.63it/s, loss=0.782]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 178/200 | Train Loss: 1.0429 | Val Loss: 1.2519 | Val Acc: 73.48% | LR: 0.000031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 179/200: 100%|██████████| 390/390 [01:09<00:00,  5.58it/s, loss=1.155]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 179/200 | Train Loss: 1.0329 | Val Loss: 1.3694 | Val Acc: 73.07% | LR: 0.000028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 180/200: 100%|██████████| 390/390 [01:10<00:00,  5.53it/s, loss=0.670]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 180/200 | Train Loss: 1.0399 | Val Loss: 1.2717 | Val Acc: 73.17% | LR: 0.000026\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v4_standard_kd_epoch180.pth\n",
            "  Cleaned up: student_v4_standard_kd_epoch180.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 181/200: 100%|██████████| 390/390 [01:10<00:00,  5.57it/s, loss=1.167]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 181/200 | Train Loss: 1.0405 | Val Loss: 1.3936 | Val Acc: 73.11% | LR: 0.000023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 182/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=1.156]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 182/200 | Train Loss: 1.0328 | Val Loss: 1.3015 | Val Acc: 73.25% | LR: 0.000021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 183/200: 100%|██████████| 390/390 [01:11<00:00,  5.43it/s, loss=0.617]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 183/200 | Train Loss: 1.0169 | Val Loss: 1.2441 | Val Acc: 73.73% | LR: 0.000019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 184/200: 100%|██████████| 390/390 [01:09<00:00,  5.61it/s, loss=0.963]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 184/200 | Train Loss: 1.0426 | Val Loss: 1.3018 | Val Acc: 73.40% | LR: 0.000017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 185/200: 100%|██████████| 390/390 [01:09<00:00,  5.62it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 185/200 | Train Loss: 1.0302 | Val Loss: 1.2726 | Val Acc: 73.73% | LR: 0.000015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 186/200: 100%|██████████| 390/390 [01:08<00:00,  5.67it/s, loss=0.732]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 186/200 | Train Loss: 1.0300 | Val Loss: 1.2137 | Val Acc: 74.09% | LR: 0.000013\n",
            "  ★ New best model saved! Accuracy: 74.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 187/200: 100%|██████████| 390/390 [01:09<00:00,  5.61it/s, loss=1.429]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 187/200 | Train Loss: 1.0205 | Val Loss: 1.2283 | Val Acc: 73.99% | LR: 0.000011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 188/200: 100%|██████████| 390/390 [01:10<00:00,  5.56it/s, loss=1.549]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 188/200 | Train Loss: 1.0250 | Val Loss: 1.2617 | Val Acc: 73.59% | LR: 0.000009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 189/200: 100%|██████████| 390/390 [01:08<00:00,  5.66it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 189/200 | Train Loss: 1.0361 | Val Loss: 1.2678 | Val Acc: 73.64% | LR: 0.000008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 190/200: 100%|██████████| 390/390 [01:08<00:00,  5.65it/s, loss=0.697]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 190/200 | Train Loss: 1.0093 | Val Loss: 1.3414 | Val Acc: 73.63% | LR: 0.000006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 191/200: 100%|██████████| 390/390 [01:08<00:00,  5.67it/s, loss=1.045]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 191/200 | Train Loss: 1.0189 | Val Loss: 1.2436 | Val Acc: 73.97% | LR: 0.000005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 192/200: 100%|██████████| 390/390 [01:09<00:00,  5.62it/s, loss=0.674]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 192/200 | Train Loss: 1.0175 | Val Loss: 1.2891 | Val Acc: 73.73% | LR: 0.000004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 193/200: 100%|██████████| 390/390 [01:08<00:00,  5.69it/s, loss=1.000]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 193/200 | Train Loss: 1.0218 | Val Loss: 1.2576 | Val Acc: 73.82% | LR: 0.000003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 194/200: 100%|██████████| 390/390 [01:08<00:00,  5.65it/s, loss=1.155]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 194/200 | Train Loss: 1.0283 | Val Loss: 1.2374 | Val Acc: 74.07% | LR: 0.000002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 195/200: 100%|██████████| 390/390 [01:09<00:00,  5.62it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 195/200 | Train Loss: 1.0276 | Val Loss: 1.2362 | Val Acc: 73.82% | LR: 0.000002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 196/200: 100%|██████████| 390/390 [01:08<00:00,  5.67it/s, loss=0.686]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 196/200 | Train Loss: 1.0254 | Val Loss: 1.2281 | Val Acc: 73.89% | LR: 0.000001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 197/200: 100%|██████████| 390/390 [01:08<00:00,  5.67it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 197/200 | Train Loss: 1.0177 | Val Loss: 1.2182 | Val Acc: 74.02% | LR: 0.000001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 198/200: 100%|██████████| 390/390 [01:08<00:00,  5.68it/s, loss=1.039]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 198/200 | Train Loss: 1.0422 | Val Loss: 1.2757 | Val Acc: 73.66% | LR: 0.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 199/200: 100%|██████████| 390/390 [01:11<00:00,  5.44it/s, loss=0.829]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 199/200 | Train Loss: 1.0183 | Val Loss: 1.2129 | Val Acc: 74.00% | LR: 0.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 200/200: 100%|██████████| 390/390 [00:55<00:00,  6.98it/s, loss=NaN-skip]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200/200 | Train Loss: 1.0146 | Val Loss: 1.2770 | Val Acc: 73.64% | LR: 0.000000\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v4_standard_kd_epoch200.pth\n",
            "  Cleaned up: student_v4_standard_kd_epoch200.pth\n",
            "\n",
            "==================================================\n",
            "Training complete. Best accuracy: 74.09%\n",
            "==================================================\n",
            "\n",
            "Student v4 (Standard KD) Final Accuracy: 74.09%\n",
            "Predicted: 74.50% | Actual: 74.09%\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Train Student with Standard KD (Version 4 - Grand Finale)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STUDENT MODEL with Standard KD (Version 4 - Grand Finale)\")\n",
        "print(\"=\"*70)\n",
        "print(\"Strategy: Best Teacher (v3) + Best KD Method (Standard KD from v2)\")\n",
        "\n",
        "student_path = MODEL_DIR / f\"{STUDENT_NAME}.pth\"\n",
        "\n",
        "if student_path.exists():\n",
        "    print(f\"Found existing Student v4: {student_path}\")\n",
        "    student_model.load_state_dict(torch.load(student_path, map_location=device))\n",
        "    distilled_accuracy, _ = evaluate_model_with_loss(student_model, testloader, nn.CrossEntropyLoss())\n",
        "    print(f\"Student v4 (Standard KD) Accuracy: {distilled_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(f\"\\nStarting Standard Knowledge Distillation (v4)...\")\n",
        "    print(f\"  Using Standard KD (NOT DKD) - proven 98% retention rate\")\n",
        "    print(f\"  KD Alpha (soft loss weight): {KD_ALPHA}\")\n",
        "    print(f\"  Temperature: {TEMPERATURE}\")\n",
        "    print(f\"  Label Smoothing: {LABEL_SMOOTHING}\")\n",
        "    print(f\"  LR Warmup: {WARMUP_EPOCHS} epochs\")\n",
        "    print(f\"  Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\")\n",
        "    \n",
        "    # Re-initialize student model (fresh weights from ImageNet)\n",
        "    student_model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
        "    student_model.classifier[1] = nn.Linear(student_model.classifier[1].in_features, NUM_CLASSES)\n",
        "    student_model = student_model.to(device)\n",
        "    \n",
        "    # Optimizer & Scheduler\n",
        "    opt_s = optim.AdamW(student_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    sch_s = optim.lr_scheduler.CosineAnnealingLR(opt_s, T_max=NUM_EPOCHS - WARMUP_EPOCHS)\n",
        "    \n",
        "    # Run Standard KD Training (NOT DKD)\n",
        "    trained_student, distilled_history = train_model_v3(\n",
        "        model=student_model,\n",
        "        dataloader=trainloader,\n",
        "        optimizer=opt_s,\n",
        "        scheduler=sch_s,\n",
        "        num_epochs=NUM_EPOCHS,\n",
        "        model_name=STUDENT_NAME,\n",
        "        teacher_model=teacher_model,\n",
        "        use_dkd=False,  # KEY: Use Standard KD, not DKD\n",
        "        temperature=TEMPERATURE,\n",
        "        label_smoothing=LABEL_SMOOTHING,\n",
        "        patience=PATIENCE,\n",
        "        warmup_epochs=WARMUP_EPOCHS\n",
        "    )\n",
        "    \n",
        "    distilled_accuracy, _ = evaluate_model_with_loss(trained_student, testloader, nn.CrossEntropyLoss())\n",
        "    print(f\"\\nStudent v4 (Standard KD) Final Accuracy: {distilled_accuracy:.2f}%\")\n",
        "    \n",
        "    # Compare with prediction\n",
        "    predicted = 76.02 * 0.98\n",
        "    print(f\"Predicted: {predicted:.2f}% | Actual: {distilled_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "VERSION 4 RESULTS - Grand Finale (Best Teacher + Best KD)\n",
            "================================================================================\n",
            "\n",
            "┌─────────────────────────────────────────────────────────────────────┐\n",
            "│                    MODEL COMPARISON TABLE                           │\n",
            "├──────────────────────────────┬──────────────┬───────────────────────┤\n",
            "│ Model                        │ Accuracy (%) │ Notes                 │\n",
            "├──────────────────────────────┼──────────────┼───────────────────────┤\n",
            "│ Teacher v3 (EfficientNet-L)  │        76.02 │ Extended training     │\n",
            "│ Student v4 Standard KD       │        74.09 │ Best Teacher + Best KD│\n",
            "├──────────────────────────────┴──────────────┴───────────────────────┤\n",
            "│                    ALL VERSIONS COMPARISON                          │\n",
            "├──────────────────────────────┬──────────────┬───────────────────────┤\n",
            "│ Student v1 (Baseline)        │        72.34 │ Standard KD           │\n",
            "│ Student v2 (Enhanced)        │        74.20 │ + AutoAug + Warmup    │\n",
            "│ Student v3 (DKD β=8.0)       │        72.69 │ Over-regularized      │\n",
            "│ Student v3.1 (DKD β=2.0)     │        73.98 │ Tuned DKD             │\n",
            "│ Student v4 (Grand Finale)    │        74.09 │ ★ BEST RESULT ★       │\n",
            "└──────────────────────────────┴──────────────┴───────────────────────┘\n",
            "\n",
            "================================================================================\n",
            "VERSION 4 ANALYSIS:\n",
            "  Teacher v3 Accuracy:       76.02%\n",
            "  Student v4 Accuracy:       74.09%\n",
            "  Gap from Teacher:          -1.93%\n",
            "  Teacher Retention:         97.5%\n",
            "\n",
            "  vs Previous Best (v2):     -0.11%\n",
            "================================================================================\n",
            "\n",
            "Version 4 Strategy:\n",
            "  ✓ Best Teacher: Teacher v3 (76.02%)\n",
            "  ✓ Best KD Method: Standard KD (α=0.7, T=4.0)\n",
            "  ✓ Best Augmentation: AutoAugment + Mixup/CutMix\n",
            "  ✓ Hypothesis: 98% retention → 74.50% expected\n",
            "\n",
            "Model Files:\n",
            "  Teacher v3:   outputs\\models\\teacher_v3.pth\n",
            "  Student v4:   outputs\\models\\student_v4_standard_kd.pth\n",
            "\n",
            "Checkpoints: d:\\Projects\\MasterProject\\code\\outputs\\checkpoints\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Results Summary (Version 4 - Grand Finale)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"VERSION 4 RESULTS - Grand Finale (Best Teacher + Best KD)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Evaluate all available models for comparison\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"\\n┌─────────────────────────────────────────────────────────────────────┐\")\n",
        "print(\"│                    MODEL COMPARISON TABLE                           │\")\n",
        "print(\"├──────────────────────────────┬──────────────┬───────────────────────┤\")\n",
        "print(\"│ Model                        │ Accuracy (%) │ Notes                 │\")\n",
        "print(\"├──────────────────────────────┼──────────────┼───────────────────────┤\")\n",
        "\n",
        "# Teacher v3\n",
        "try:\n",
        "    print(f\"│ Teacher v3 (EfficientNet-L)  │ {teacher_accuracy:12.2f} │ Extended training     │\")\n",
        "except NameError:\n",
        "    print(f\"│ Teacher v3 (EfficientNet-L)  │        76.02 │ Extended training     │\")\n",
        "\n",
        "# Student v4 (Standard KD with strong teacher)\n",
        "try:\n",
        "    print(f\"│ Student v4 Standard KD       │ {distilled_accuracy:12.2f} │ Best Teacher + Best KD│\")\n",
        "except NameError:\n",
        "    print(f\"│ Student v4 Standard KD       │ {'N/A':>12} │                       │\")\n",
        "\n",
        "print(\"├──────────────────────────────┴──────────────┴───────────────────────┤\")\n",
        "print(\"│                    ALL VERSIONS COMPARISON                          │\")\n",
        "print(\"├──────────────────────────────┬──────────────┬───────────────────────┤\")\n",
        "print(\"│ Student v1 (Baseline)        │        72.34 │ Standard KD           │\")\n",
        "print(\"│ Student v2 (Enhanced)        │        74.20 │ + AutoAug + Warmup    │\")\n",
        "print(\"│ Student v3 (DKD β=8.0)       │        72.69 │ Over-regularized      │\")\n",
        "print(\"│ Student v3.1 (DKD β=2.0)     │        73.98 │ Tuned DKD             │\")\n",
        "try:\n",
        "    print(f\"│ Student v4 (Grand Finale)    │ {distilled_accuracy:12.2f} │ ★ BEST RESULT ★       │\")\n",
        "except NameError:\n",
        "    print(f\"│ Student v4 (Grand Finale)    │ {'TBD':>12} │ ★ Target: 74.50% ★    │\")\n",
        "print(\"└──────────────────────────────┴──────────────┴───────────────────────┘\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"VERSION 4 ANALYSIS:\")\n",
        "try:\n",
        "    gap = distilled_accuracy - teacher_accuracy\n",
        "    retention = (distilled_accuracy / teacher_accuracy) * 100\n",
        "    print(f\"  Teacher v3 Accuracy:       {teacher_accuracy:.2f}%\")\n",
        "    print(f\"  Student v4 Accuracy:       {distilled_accuracy:.2f}%\")\n",
        "    print(f\"  Gap from Teacher:          {gap:+.2f}%\")\n",
        "    print(f\"  Teacher Retention:         {retention:.1f}%\")\n",
        "    \n",
        "    # Compare with previous best (v2)\n",
        "    v2_accuracy = 74.20\n",
        "    improvement = distilled_accuracy - v2_accuracy\n",
        "    print(f\"\\n  vs Previous Best (v2):     {improvement:+.2f}%\")\n",
        "    \n",
        "    if distilled_accuracy > v2_accuracy:\n",
        "        print(f\"\\n  🎉 NEW RECORD ACHIEVED! 🎉\")\n",
        "except NameError:\n",
        "    print(\"  Run training cells first to see results.\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nVersion 4 Strategy:\")\n",
        "print(f\"  ✓ Best Teacher: Teacher v3 (76.02%)\")\n",
        "print(f\"  ✓ Best KD Method: Standard KD (α={KD_ALPHA}, T={TEMPERATURE})\")\n",
        "print(f\"  ✓ Best Augmentation: AutoAugment + Mixup/CutMix\")\n",
        "print(f\"  ✓ Hypothesis: 98% retention → 74.50% expected\")\n",
        "\n",
        "print(f\"\\nModel Files:\")\n",
        "print(f\"  Teacher v3:   {MODEL_DIR / TEACHER_NAME}.pth\")\n",
        "print(f\"  Student v4:   {MODEL_DIR / STUDENT_NAME}.pth\")\n",
        "print(f\"\\nCheckpoints: {CHECKPOINT_DIR.absolute()}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "my-gpu-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
