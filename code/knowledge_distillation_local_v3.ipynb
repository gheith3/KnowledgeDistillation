{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Knowledge Distillation for EfficientNetV2 on CIFAR-100 - Version 3.1 (Tuned DKD)\n",
        "\n",
        "This notebook implements **State-of-the-Art** knowledge distillation with:\n",
        "\n",
        "- **Decoupled Knowledge Distillation (DKD)** - Separates target and non-target class knowledge (Zhao et al., CVPR 2022)\n",
        "- **AutoAugment + Random Erasing** - Advanced data augmentation\n",
        "- **CutMix + Mixup** - Sample mixing strategies\n",
        "- **Label Smoothing + LR Warmup** - Training stability\n",
        "\n",
        "---\n",
        "\n",
        "## Version History:\n",
        "\n",
        "- **v1 (Baseline):** Standard KD + CutMix/Mixup → 72.34% accuracy\n",
        "- **v2 (Enhanced):** + AutoAugment + Label Smoothing + LR Warmup → 74.20% accuracy\n",
        "- **v3 (DKD):** + Decoupled Knowledge Distillation (β=8.0) → 72.69% (over-regularized)\n",
        "- **v3.1 (Tuned DKD):** Reduced β from 8.0 to 2.0 → Target: 75%+ accuracy\n",
        "\n",
        "---\n",
        "\n",
        "## Key Changes in v3.1:\n",
        "\n",
        "1. **Reduced DKD_BETA** from 8.0 to 2.0 (less aggressive NCKD weight)\n",
        "2. **Reuse Teacher v3** (76.02% accuracy) - no retraining needed\n",
        "3. **New student model name:** `student_v3_1_dkd_beta2`\n",
        "\n",
        "**Diagnosis:** v3 suffered from over-regularization due to high β combined with strong augmentation (Mixup/CutMix).\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directories ready at: d:\\Projects\\MasterProject\\code\\outputs\n",
            "Using device: cuda\n",
            "GPU: NVIDIA GeForce RTX 5070 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup and Imports\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import efficientnet_v2_s, efficientnet_v2_l, EfficientNet_V2_S_Weights, EfficientNet_V2_L_Weights\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup Directories (Local paths)\n",
        "PROJECT_ROOT = Path('./outputs')\n",
        "MODEL_DIR = PROJECT_ROOT / 'models'\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "CHECKPOINT_DIR = PROJECT_ROOT / 'checkpoints'\n",
        "\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Directories ready at: {PROJECT_ROOT.absolute()}\")\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "VERSION 3.1 CONFIG - Tuned Beta Parameter\n",
            "============================================================\n",
            "Teacher: teacher_v3 (Accuracy: 76.02%)\n",
            "Training: Epochs=200 | Batch=128 | LR=0.001\n",
            "DKD: Alpha(TCKD)=1.0, Beta(NCKD)=2.0 (REDUCED from 8.0)\n",
            "Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\n",
            "Student Model: student_v3_1_dkd_beta2\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Experiment Configuration (Version 3.1 - Tuned DKD Beta)\n",
        "# ==========================================\n",
        "# HYPERPARAMETERS\n",
        "# ==========================================\n",
        "NUM_EPOCHS = 200\n",
        "TEACHER_EPOCHS = 300        # Extended teacher training for v3\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.05\n",
        "PATIENCE = 30\n",
        "WARMUP_EPOCHS = 5           # LR warmup\n",
        "\n",
        "# Distillation Params (DKD - Tuned for v3.1)\n",
        "DKD_ALPHA = 1.0             # Weight for Target Class Knowledge Distillation (TCKD)\n",
        "DKD_BETA = 2.0              # REDUCED from 8.0 to 2.0 - Less aggressive NCKD\n",
        "TEMPERATURE = 4.0           # Softmax Temperature\n",
        "LABEL_SMOOTHING = 0.1       # Label smoothing for hard loss\n",
        "\n",
        "# Augmentation Params\n",
        "MIXUP_ALPHA = 0.8\n",
        "CUTMIX_ALPHA = 1.0\n",
        "CHECKPOINT_FREQUENCY = 20\n",
        "NUM_CLASSES = 100\n",
        "\n",
        "# Version 3.1 Model Names\n",
        "TEACHER_NAME = \"teacher_v3\"              # Reuse the strong teacher (76.02%)\n",
        "STUDENT_NAME = \"student_v3_1_dkd_beta2\"  # New student with tuned beta\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"VERSION 3.1 CONFIG - Tuned Beta Parameter\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Teacher: {TEACHER_NAME} (Accuracy: 76.02%)\")\n",
        "print(f\"Training: Epochs={NUM_EPOCHS} | Batch={BATCH_SIZE} | LR={LEARNING_RATE}\")\n",
        "print(f\"DKD: Alpha(TCKD)={DKD_ALPHA}, Beta(NCKD)={DKD_BETA} (REDUCED from 8.0)\")\n",
        "print(f\"Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\")\n",
        "print(f\"Student Model: {STUDENT_NAME}\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded: 50000 Training, 10000 Test images\n",
            "  Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Data Loading (Enhanced with AutoAugment + RandomErasing)\n",
        "from torchvision.transforms import autoaugment\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    autoaugment.AutoAugment(policy=autoaugment.AutoAugmentPolicy.CIFAR10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.2)),  # Cutout-like augmentation\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root=str(DATA_DIR), train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, \n",
        "                                          num_workers=4, pin_memory=True, drop_last=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root=str(DATA_DIR), train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, \n",
        "                                         num_workers=4, pin_memory=True)\n",
        "\n",
        "print(f\"Data loaded: {len(trainset)} Training, {len(testset)} Test images\")\n",
        "print(f\"  Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions loaded:\n",
            "  - DKD Loss (Decoupled Knowledge Distillation)\n",
            "  - Standard KD Loss (for comparison)\n",
            "  - CutMix, Mixup augmentations\n",
            "  - Checkpoint utilities\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Helper Functions (DKD Loss + Augmentations + Utilities)\n",
        "\n",
        "# ==========================================\n",
        "# 1. Decoupled Knowledge Distillation (DKD) Loss\n",
        "# Based on: Zhao et al. \"Decoupled Knowledge Distillation\", CVPR 2022\n",
        "# https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Decoupled_Knowledge_Distillation_CVPR_2022_paper.pdf\n",
        "# ==========================================\n",
        "\n",
        "def _get_gt_mask(logits, target):\n",
        "    \"\"\"Get mask for target (ground truth) class\"\"\"\n",
        "    target = target.reshape(-1)\n",
        "    mask = torch.zeros_like(logits).scatter_(1, target.unsqueeze(1), 1).bool()\n",
        "    return mask\n",
        "\n",
        "def _get_other_mask(logits, target):\n",
        "    \"\"\"Get mask for non-target classes\"\"\"\n",
        "    target = target.reshape(-1)\n",
        "    mask = torch.ones_like(logits).scatter_(1, target.unsqueeze(1), 0).bool()\n",
        "    return mask\n",
        "\n",
        "def cat_mask(t, mask1, mask2):\n",
        "    \"\"\"Concatenate masked values\"\"\"\n",
        "    t1 = (t * mask1).sum(dim=1, keepdims=True)\n",
        "    t2 = (t * mask2).sum(1, keepdims=True)\n",
        "    rt = torch.cat([t1, t2], dim=1)\n",
        "    return rt\n",
        "\n",
        "def dkd_loss(student_logits, teacher_logits, target, alpha=1.0, beta=8.0, temperature=4.0):\n",
        "    \"\"\"\n",
        "    Decoupled Knowledge Distillation (DKD) Loss.\n",
        "    \n",
        "    Separates knowledge into:\n",
        "    - TCKD (Target Class Knowledge Distillation): Knowledge about the correct class\n",
        "    - NCKD (Non-Target Class Knowledge Distillation): Knowledge about class relationships\n",
        "    \n",
        "    Args:\n",
        "        student_logits: Student model outputs\n",
        "        teacher_logits: Teacher model outputs\n",
        "        target: Ground truth labels\n",
        "        alpha: Weight for TCKD (default: 1.0)\n",
        "        beta: Weight for NCKD (default: 8.0, crucial for performance)\n",
        "        temperature: Softmax temperature (default: 4.0)\n",
        "    \n",
        "    Returns:\n",
        "        Combined DKD loss\n",
        "    \"\"\"\n",
        "    # Get masks for target and non-target classes\n",
        "    gt_mask = _get_gt_mask(student_logits, target)\n",
        "    other_mask = _get_other_mask(student_logits, target)\n",
        "    \n",
        "    # Calculate probabilities with temperature scaling\n",
        "    pred_student = F.softmax(student_logits / temperature, dim=1)\n",
        "    pred_teacher = F.softmax(teacher_logits / temperature, dim=1)\n",
        "    \n",
        "    # Separate target and non-target probabilities\n",
        "    pred_student_cat = cat_mask(pred_student, gt_mask, other_mask)\n",
        "    pred_teacher_cat = cat_mask(pred_teacher, gt_mask, other_mask)\n",
        "    \n",
        "    # Target Class Knowledge Distillation (TCKD)\n",
        "    log_pred_student = torch.log(pred_student_cat + 1e-8)\n",
        "    tckd_loss = (\n",
        "        F.kl_div(log_pred_student, pred_teacher_cat, reduction='batchmean')\n",
        "        * (temperature ** 2)\n",
        "    )\n",
        "    \n",
        "    # Non-Target Class Knowledge Distillation (NCKD)\n",
        "    # Mask out target class with large negative value\n",
        "    pred_teacher_part2 = F.softmax(\n",
        "        teacher_logits / temperature - 1000.0 * gt_mask, dim=1\n",
        "    )\n",
        "    log_pred_student_part2 = F.log_softmax(\n",
        "        student_logits / temperature - 1000.0 * gt_mask, dim=1\n",
        "    )\n",
        "    \n",
        "    nckd_loss = (\n",
        "        F.kl_div(log_pred_student_part2, pred_teacher_part2, reduction='batchmean')\n",
        "        * (temperature ** 2)\n",
        "    )\n",
        "    \n",
        "    # Combined DKD loss\n",
        "    return alpha * tckd_loss + beta * nckd_loss\n",
        "\n",
        "def dkd_loss_mixup(student_logits, teacher_logits, labels_a, labels_b, lam,\n",
        "                   alpha=1.0, beta=8.0, temperature=4.0, label_smoothing=0.1):\n",
        "    \"\"\"\n",
        "    DKD Loss for mixed samples (CutMix/Mixup compatible)\n",
        "    Uses weighted combination of DKD losses for both label sets\n",
        "    \"\"\"\n",
        "    # DKD for both label sets\n",
        "    dkd_a = dkd_loss(student_logits, teacher_logits, labels_a, alpha, beta, temperature)\n",
        "    dkd_b = dkd_loss(student_logits, teacher_logits, labels_b, alpha, beta, temperature)\n",
        "    \n",
        "    # Weighted DKD loss\n",
        "    soft_loss = lam * dkd_a + (1 - lam) * dkd_b\n",
        "    \n",
        "    # Hard loss with label smoothing\n",
        "    hard_loss = lam * F.cross_entropy(student_logits, labels_a, label_smoothing=label_smoothing) + \\\n",
        "                (1 - lam) * F.cross_entropy(student_logits, labels_b, label_smoothing=label_smoothing)\n",
        "    \n",
        "    # Combined loss (DKD already weighted by alpha/beta, so we just add hard loss)\n",
        "    # Using 0.1 weight for hard loss to not overpower DKD\n",
        "    loss = soft_loss + 0.1 * hard_loss\n",
        "    \n",
        "    # NaN safety check\n",
        "    if torch.isnan(loss):\n",
        "        return hard_loss\n",
        "    \n",
        "    return loss\n",
        "\n",
        "# ==========================================\n",
        "# 2. Standard KD Loss (kept for comparison)\n",
        "# ==========================================\n",
        "def kd_loss(student_logits, teacher_logits, labels, temp=4.0, alpha=0.7, label_smoothing=0.1):\n",
        "    \"\"\"Standard Knowledge Distillation Loss (for comparison)\"\"\"\n",
        "    soft_student = F.log_softmax(student_logits / temp, dim=1)\n",
        "    soft_teacher = F.softmax(teacher_logits / temp, dim=1)\n",
        "    soft_loss = F.kl_div(soft_student, soft_teacher, reduction='batchmean') * (temp ** 2)\n",
        "    hard_loss = F.cross_entropy(student_logits, labels, label_smoothing=label_smoothing)\n",
        "    return alpha * soft_loss + (1 - alpha) * hard_loss\n",
        "\n",
        "# ==========================================\n",
        "# 3. Augmentations: Mixup & CutMix\n",
        "# ==========================================\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = int(W * cut_rat)\n",
        "    cut_h = int(H * cut_rat)\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "def cutmix_data(x, y, alpha=1.0):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
        "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
        "    y_a, y_b = y, y[index]\n",
        "    return x, y_a, y_b, lam\n",
        "\n",
        "# ==========================================\n",
        "# 4. Utilities (Save/Load/Evaluate)\n",
        "# ==========================================\n",
        "def evaluate_model_with_loss(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    acc = 100 * correct / total\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "    return acc, avg_loss\n",
        "\n",
        "def save_checkpoint(model, optimizer, scheduler, epoch, best_acc, history, model_name, epochs_no_improve):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'best_acc': best_acc,\n",
        "        'history': history,\n",
        "        'epochs_no_improve': epochs_no_improve\n",
        "    }\n",
        "    path = CHECKPOINT_DIR / f\"{model_name}_epoch{epoch+1}.pth\"\n",
        "    torch.save(checkpoint, path)\n",
        "    print(f\"  Checkpoint saved: {path}\")\n",
        "    \n",
        "def load_checkpoint(model, optimizer, scheduler, model_name):\n",
        "    checkpoints = sorted(glob.glob(str(CHECKPOINT_DIR / f\"{model_name}_epoch*.pth\")))\n",
        "    if not checkpoints:\n",
        "        return None\n",
        "    latest = checkpoints[-1]\n",
        "    print(f\"  Loading checkpoint: {latest}\")\n",
        "    checkpoint = torch.load(latest, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    return checkpoint\n",
        "\n",
        "def cleanup_old_checkpoints(model_name, keep=3):\n",
        "    checkpoints = sorted(glob.glob(str(CHECKPOINT_DIR / f\"{model_name}_epoch*.pth\")))\n",
        "    if len(checkpoints) > keep:\n",
        "        for chk in checkpoints[:-keep]:\n",
        "            os.remove(chk)\n",
        "            print(f\"  Cleaned up: {os.path.basename(chk)}\")\n",
        "\n",
        "print(\"Helper functions loaded:\")\n",
        "print(\"  - DKD Loss (Decoupled Knowledge Distillation)\")\n",
        "print(\"  - Standard KD Loss (for comparison)\")\n",
        "print(\"  - CutMix, Mixup augmentations\")\n",
        "print(\"  - Checkpoint utilities\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training function loaded (Version 3: DKD + LR Warmup + Label Smoothing)\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Training Loop (Version 3 - with DKD support)\n",
        "def train_model_v3(model, dataloader, optimizer, scheduler, num_epochs, model_name, \n",
        "                   teacher_model=None, use_dkd=True,\n",
        "                   dkd_alpha=1.0, dkd_beta=8.0, temperature=4.0, label_smoothing=0.1,\n",
        "                   patience=30, grad_clip=1.0, warmup_epochs=5):\n",
        "    \"\"\"\n",
        "    Version 3 Training loop with:\n",
        "    - Decoupled Knowledge Distillation (DKD) loss\n",
        "    - CutMix/Mixup augmentation\n",
        "    - Learning Rate Warmup\n",
        "    - Mixed precision training\n",
        "    - Gradient clipping\n",
        "    - NaN detection and recovery\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. Load Checkpoint\n",
        "    checkpoint = load_checkpoint(model, optimizer, scheduler, model_name)\n",
        "    if checkpoint:\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        history = checkpoint['history']\n",
        "        epochs_no_improve = checkpoint['epochs_no_improve']\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        print(f\"  Resuming from epoch {start_epoch}, Best Acc: {best_acc:.2f}%\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        best_acc = 0.0\n",
        "        history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
        "        epochs_no_improve = 0\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        print(f\"  Starting fresh training...\")\n",
        "\n",
        "    # 2. Setup\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
        "    val_criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Store base LR for warmup\n",
        "    base_lr = optimizer.param_groups[0]['lr']\n",
        "    \n",
        "    if teacher_model:\n",
        "        teacher_model.eval()\n",
        "        for param in teacher_model.parameters():\n",
        "            param.requires_grad = False\n",
        "        loss_type = \"DKD\" if use_dkd else \"Standard KD\"\n",
        "        print(f\"  Using {loss_type} loss with Teacher guidance\")\n",
        "\n",
        "    # 3. Training Loop\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        valid_batches = 0\n",
        "        \n",
        "        # Learning Rate Warmup\n",
        "        if epoch < warmup_epochs:\n",
        "            warmup_lr = base_lr * (epoch + 1) / warmup_epochs\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = warmup_lr\n",
        "        \n",
        "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        \n",
        "        for inputs, labels in loop:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            # Randomly choose Mixup (50%) or CutMix (50%)\n",
        "            use_cutmix = np.random.rand() > 0.5\n",
        "            if use_cutmix:\n",
        "                inputs_aug, labels_a, labels_b, lam = cutmix_data(inputs.clone(), labels, alpha=CUTMIX_ALPHA)\n",
        "            else:\n",
        "                inputs_aug, labels_a, labels_b, lam = mixup_data(inputs, labels, alpha=MIXUP_ALPHA)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                # Student Forward\n",
        "                student_outputs = model(inputs_aug)\n",
        "                \n",
        "                # Loss Calculation\n",
        "                if teacher_model:\n",
        "                    # Teacher Forward (no grad)\n",
        "                    with torch.no_grad():\n",
        "                        teacher_outputs = teacher_model(inputs_aug)\n",
        "                    \n",
        "                    if use_dkd:\n",
        "                        # DKD Loss (Version 3)\n",
        "                        loss = dkd_loss_mixup(\n",
        "                            student_outputs, teacher_outputs, \n",
        "                            labels_a, labels_b, lam,\n",
        "                            alpha=dkd_alpha, beta=dkd_beta, \n",
        "                            temperature=temperature, label_smoothing=label_smoothing\n",
        "                        )\n",
        "                    else:\n",
        "                        # Standard KD Loss (for comparison)\n",
        "                        loss = lam * kd_loss(student_outputs, teacher_outputs, labels_a, temperature, 0.7, label_smoothing) + \\\n",
        "                               (1 - lam) * kd_loss(student_outputs, teacher_outputs, labels_b, temperature, 0.7, label_smoothing)\n",
        "                else:\n",
        "                    # Standard CE with Label Smoothing for Teacher training\n",
        "                    loss = lam * F.cross_entropy(student_outputs, labels_a, label_smoothing=label_smoothing) + \\\n",
        "                           (1 - lam) * F.cross_entropy(student_outputs, labels_b, label_smoothing=label_smoothing)\n",
        "            \n",
        "            # Skip batch if loss is NaN\n",
        "            if torch.isnan(loss):\n",
        "                loop.set_postfix(loss=\"NaN-skip\")\n",
        "                continue\n",
        "            \n",
        "            # Backward\n",
        "            scaler.scale(loss).backward()\n",
        "            \n",
        "            if grad_clip > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                \n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            valid_batches += 1\n",
        "            loop.set_postfix(loss=f\"{loss.item():.3f}\")\n",
        "\n",
        "        # Step Scheduler (only after warmup)\n",
        "        if epoch >= warmup_epochs:\n",
        "            scheduler.step()\n",
        "        \n",
        "        # Validation\n",
        "        train_loss = running_loss / max(valid_batches, 1)\n",
        "        val_acc, val_loss = evaluate_model_with_loss(model, testloader, val_criterion)\n",
        "        \n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_accuracy'].append(val_acc)\n",
        "        \n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | LR: {current_lr:.6f}\")\n",
        "        \n",
        "        # Save Best\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), MODEL_DIR / f\"{model_name}.pth\")\n",
        "            epochs_no_improve = 0\n",
        "            print(f\"  ★ New best model saved! Accuracy: {best_acc:.2f}%\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            \n",
        "        # Checkpointing\n",
        "        if (epoch + 1) % CHECKPOINT_FREQUENCY == 0:\n",
        "            save_checkpoint(model, optimizer, scheduler, epoch, best_acc, history, model_name, epochs_no_improve)\n",
        "            cleanup_old_checkpoints(model_name)\n",
        "            \n",
        "        # Early Stopping\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "            break\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training complete. Best accuracy: {best_acc:.2f}%\")\n",
        "    print(f\"{'='*50}\")\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n",
        "\n",
        "print(\"Training function loaded (Version 3: DKD + LR Warmup + Label Smoothing)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Teacher (EfficientNetV2-L)...\n",
            "Loading Student (EfficientNetV2-S)...\n",
            "Models loaded\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Initialize Models\n",
        "print(\"Loading Teacher (EfficientNetV2-L)...\")\n",
        "teacher_model = efficientnet_v2_l(weights=EfficientNet_V2_L_Weights.IMAGENET1K_V1)\n",
        "teacher_model.classifier[1] = nn.Linear(teacher_model.classifier[1].in_features, NUM_CLASSES)\n",
        "teacher_model = teacher_model.to(device)\n",
        "\n",
        "print(\"Loading Student (EfficientNetV2-S)...\")\n",
        "student_model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
        "student_model.classifier[1] = nn.Linear(student_model.classifier[1].in_features, NUM_CLASSES)\n",
        "student_model = student_model.to(device)\n",
        "\n",
        "print(\"Models loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TEACHER MODEL (Version 3)\n",
            "======================================================================\n",
            "Found existing Teacher v3: outputs\\models\\teacher_v3.pth\n",
            "\n",
            "Teacher v3 Accuracy: 76.02%\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Train/Load Teacher Model (Version 3)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEACHER MODEL (Version 3)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "teacher_path = MODEL_DIR / f\"{TEACHER_NAME}.pth\"\n",
        "\n",
        "# Also check for existing v1/v2 teacher to use as starting point\n",
        "existing_teacher = MODEL_DIR / \"teacher_model.pth\"\n",
        "\n",
        "if teacher_path.exists():\n",
        "    print(f\"Found existing Teacher v3: {teacher_path}\")\n",
        "    teacher_model.load_state_dict(torch.load(teacher_path, map_location=device))\n",
        "elif existing_teacher.exists():\n",
        "    print(f\"Found existing Teacher (v1/v2): {existing_teacher}\")\n",
        "    print(f\"Loading and continuing training for {TEACHER_EPOCHS} epochs...\")\n",
        "    teacher_model.load_state_dict(torch.load(existing_teacher, map_location=device))\n",
        "    \n",
        "    # Continue training with extended epochs\n",
        "    opt_t = optim.AdamW(teacher_model.parameters(), lr=LEARNING_RATE * 0.1, weight_decay=WEIGHT_DECAY)  # Lower LR for fine-tuning\n",
        "    sch_t = optim.lr_scheduler.CosineAnnealingLR(opt_t, T_max=100)  # Additional 100 epochs\n",
        "    \n",
        "    teacher_model, teacher_history = train_model_v3(\n",
        "        teacher_model, trainloader, opt_t, sch_t, \n",
        "        num_epochs=100,  # Additional epochs\n",
        "        model_name=TEACHER_NAME, \n",
        "        teacher_model=None,\n",
        "        warmup_epochs=0  # No warmup for fine-tuning\n",
        "    )\n",
        "else:\n",
        "    print(f\"Training Teacher Model v3 from scratch ({TEACHER_EPOCHS} epochs)...\")\n",
        "    print(\"This may take a while...\")\n",
        "    \n",
        "    # Re-initialize teacher\n",
        "    teacher_model = efficientnet_v2_l(weights=EfficientNet_V2_L_Weights.IMAGENET1K_V1)\n",
        "    teacher_model.classifier[1] = nn.Linear(teacher_model.classifier[1].in_features, NUM_CLASSES)\n",
        "    teacher_model = teacher_model.to(device)\n",
        "    \n",
        "    opt_t = optim.AdamW(teacher_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    sch_t = optim.lr_scheduler.CosineAnnealingLR(opt_t, T_max=TEACHER_EPOCHS - WARMUP_EPOCHS)\n",
        "    \n",
        "    teacher_model, teacher_history = train_model_v3(\n",
        "        teacher_model, trainloader, opt_t, sch_t, \n",
        "        num_epochs=TEACHER_EPOCHS, \n",
        "        model_name=TEACHER_NAME, \n",
        "        teacher_model=None,\n",
        "        warmup_epochs=WARMUP_EPOCHS\n",
        "    )\n",
        "\n",
        "# Evaluate Teacher\n",
        "teacher_model.eval()\n",
        "teacher_accuracy, _ = evaluate_model_with_loss(teacher_model, testloader, nn.CrossEntropyLoss())\n",
        "print(f\"\\nTeacher v3 Accuracy: {teacher_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STUDENT MODEL with DKD (Version 3.1 - Tuned Beta)\n",
            "======================================================================\n",
            "\n",
            "Starting Decoupled Knowledge Distillation (DKD) v3.1...\n",
            "  Key Change: DKD Beta REDUCED from 8.0 to 2.0\n",
            "  DKD Alpha (TCKD weight): 1.0\n",
            "  DKD Beta (NCKD weight): 2.0 ← REDUCED to fix over-regularization\n",
            "  Temperature: 4.0\n",
            "  Label Smoothing: 0.1\n",
            "  LR Warmup: 5 epochs\n",
            "  Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\n",
            "  Starting fresh training...\n",
            "  Using DKD loss with Teacher guidance\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/200: 100%|██████████| 390/390 [01:18<00:00,  4.99it/s, loss=1.317]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200 | Train Loss: 2.0525 | Val Loss: 3.4177 | Val Acc: 25.66% | LR: 0.000200\n",
            "  ★ New best model saved! Accuracy: 25.66%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/200: 100%|██████████| 390/390 [01:18<00:00,  4.94it/s, loss=1.340]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/200 | Train Loss: 1.8003 | Val Loss: 2.7542 | Val Acc: 39.99% | LR: 0.000400\n",
            "  ★ New best model saved! Accuracy: 39.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/200: 100%|██████████| 390/390 [01:18<00:00,  4.94it/s, loss=3.615]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/200 | Train Loss: 1.6594 | Val Loss: 2.3862 | Val Acc: 46.53% | LR: 0.000600\n",
            "  ★ New best model saved! Accuracy: 46.53%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/200: 100%|██████████| 390/390 [01:19<00:00,  4.90it/s, loss=1.017]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/200 | Train Loss: 1.6369 | Val Loss: 2.3853 | Val Acc: 46.39% | LR: 0.000800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/200: 100%|██████████| 390/390 [01:18<00:00,  4.94it/s, loss=1.168]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/200 | Train Loss: 1.6736 | Val Loss: 2.4945 | Val Acc: 45.99% | LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/200: 100%|██████████| 390/390 [01:19<00:00,  4.89it/s, loss=3.043]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/200 | Train Loss: 1.6888 | Val Loss: 2.2593 | Val Acc: 48.10% | LR: 0.001000\n",
            "  ★ New best model saved! Accuracy: 48.10%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/200: 100%|██████████| 390/390 [01:19<00:00,  4.90it/s, loss=1.057]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/200 | Train Loss: 1.6835 | Val Loss: 2.3503 | Val Acc: 48.38% | LR: 0.001000\n",
            "  ★ New best model saved! Accuracy: 48.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/200: 100%|██████████| 390/390 [01:19<00:00,  4.93it/s, loss=1.126]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/200 | Train Loss: 1.5727 | Val Loss: 2.2474 | Val Acc: 50.17% | LR: 0.000999\n",
            "  ★ New best model saved! Accuracy: 50.17%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/200: 100%|██████████| 390/390 [01:19<00:00,  4.91it/s, loss=1.057]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/200 | Train Loss: 1.5719 | Val Loss: 2.3025 | Val Acc: 49.70% | LR: 0.000999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/200: 100%|██████████| 390/390 [01:19<00:00,  4.92it/s, loss=1.029]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/200 | Train Loss: 1.6490 | Val Loss: 2.2031 | Val Acc: 49.64% | LR: 0.000998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/200: 100%|██████████| 390/390 [01:19<00:00,  4.90it/s, loss=1.079]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/200 | Train Loss: 1.5557 | Val Loss: 2.1657 | Val Acc: 53.14% | LR: 0.000998\n",
            "  ★ New best model saved! Accuracy: 53.14%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/200: 100%|██████████| 390/390 [01:19<00:00,  4.93it/s, loss=1.034]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/200 | Train Loss: 1.4955 | Val Loss: 2.0878 | Val Acc: 52.59% | LR: 0.000997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/200: 100%|██████████| 390/390 [01:19<00:00,  4.92it/s, loss=0.935]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/200 | Train Loss: 1.4254 | Val Loss: 2.2182 | Val Acc: 52.01% | LR: 0.000996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/200: 100%|██████████| 390/390 [01:18<00:00,  4.94it/s, loss=1.074]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/200 | Train Loss: 1.5974 | Val Loss: 2.1129 | Val Acc: 53.23% | LR: 0.000995\n",
            "  ★ New best model saved! Accuracy: 53.23%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/200: 100%|██████████| 390/390 [01:19<00:00,  4.93it/s, loss=0.719]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/200 | Train Loss: 1.5368 | Val Loss: 2.1317 | Val Acc: 53.67% | LR: 0.000994\n",
            "  ★ New best model saved! Accuracy: 53.67%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/200: 100%|██████████| 390/390 [01:18<00:00,  4.99it/s, loss=0.997]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/200 | Train Loss: 1.4728 | Val Loss: 1.9663 | Val Acc: 54.39% | LR: 0.000992\n",
            "  ★ New best model saved! Accuracy: 54.39%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/200: 100%|██████████| 390/390 [01:19<00:00,  4.92it/s, loss=3.353]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/200 | Train Loss: 1.3850 | Val Loss: 2.0201 | Val Acc: 54.87% | LR: 0.000991\n",
            "  ★ New best model saved! Accuracy: 54.87%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/200: 100%|██████████| 390/390 [01:18<00:00,  4.95it/s, loss=1.035]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/200 | Train Loss: 1.4523 | Val Loss: 1.9863 | Val Acc: 56.01% | LR: 0.000989\n",
            "  ★ New best model saved! Accuracy: 56.01%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/200: 100%|██████████| 390/390 [01:19<00:00,  4.92it/s, loss=0.948]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/200 | Train Loss: 1.4569 | Val Loss: 1.9722 | Val Acc: 56.36% | LR: 0.000987\n",
            "  ★ New best model saved! Accuracy: 56.36%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/200: 100%|██████████| 390/390 [01:19<00:00,  4.94it/s, loss=3.116]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/200 | Train Loss: 1.5045 | Val Loss: 2.0370 | Val Acc: 55.45% | LR: 0.000985\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v3_1_dkd_beta2_epoch20.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/200: 100%|██████████| 390/390 [01:18<00:00,  4.96it/s, loss=1.793]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/200 | Train Loss: 1.4191 | Val Loss: 1.9361 | Val Acc: 57.10% | LR: 0.000983\n",
            "  ★ New best model saved! Accuracy: 57.10%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/200: 100%|██████████| 390/390 [01:19<00:00,  4.92it/s, loss=0.936]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/200 | Train Loss: 1.4288 | Val Loss: 2.0344 | Val Acc: 57.89% | LR: 0.000981\n",
            "  ★ New best model saved! Accuracy: 57.89%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/200: 100%|██████████| 390/390 [01:18<00:00,  4.96it/s, loss=0.933]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/200 | Train Loss: 1.4974 | Val Loss: 1.9226 | Val Acc: 56.86% | LR: 0.000979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/200: 100%|██████████| 390/390 [01:18<00:00,  4.95it/s, loss=0.781]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/200 | Train Loss: 1.4637 | Val Loss: 1.9384 | Val Acc: 58.38% | LR: 0.000977\n",
            "  ★ New best model saved! Accuracy: 58.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/200: 100%|██████████| 390/390 [01:18<00:00,  4.99it/s, loss=0.882]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/200 | Train Loss: 1.3645 | Val Loss: 2.1787 | Val Acc: 57.48% | LR: 0.000974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/200: 100%|██████████| 390/390 [01:16<00:00,  5.08it/s, loss=1.721]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/200 | Train Loss: 1.4195 | Val Loss: 1.9112 | Val Acc: 57.86% | LR: 0.000972\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/200: 100%|██████████| 390/390 [01:16<00:00,  5.11it/s, loss=1.827]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/200 | Train Loss: 1.4244 | Val Loss: 1.8281 | Val Acc: 59.89% | LR: 0.000969\n",
            "  ★ New best model saved! Accuracy: 59.89%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/200: 100%|██████████| 390/390 [01:16<00:00,  5.11it/s, loss=0.964]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/200 | Train Loss: 1.3793 | Val Loss: 1.7975 | Val Acc: 62.03% | LR: 0.000966\n",
            "  ★ New best model saved! Accuracy: 62.03%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/200: 100%|██████████| 390/390 [01:17<00:00,  5.04it/s, loss=0.837]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/200 | Train Loss: 1.4469 | Val Loss: 1.7815 | Val Acc: 60.74% | LR: 0.000963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=3.117]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/200 | Train Loss: 1.4271 | Val Loss: 1.8985 | Val Acc: 58.96% | LR: 0.000960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=0.788]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31/200 | Train Loss: 1.4162 | Val Loss: 1.7714 | Val Acc: 60.47% | LR: 0.000957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.822]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32/200 | Train Loss: 1.4662 | Val Loss: 1.8845 | Val Acc: 59.39% | LR: 0.000953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=1.703]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33/200 | Train Loss: 1.3888 | Val Loss: 1.8268 | Val Acc: 60.36% | LR: 0.000950\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=0.741]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34/200 | Train Loss: 1.3918 | Val Loss: 1.7756 | Val Acc: 60.76% | LR: 0.000946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=2.324]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35/200 | Train Loss: 1.3837 | Val Loss: 1.7707 | Val Acc: 60.47% | LR: 0.000943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.878]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36/200 | Train Loss: 1.3809 | Val Loss: 1.8257 | Val Acc: 61.40% | LR: 0.000939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/200: 100%|██████████| 390/390 [01:13<00:00,  5.34it/s, loss=0.890]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37/200 | Train Loss: 1.4053 | Val Loss: 1.8161 | Val Acc: 60.80% | LR: 0.000935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=1.742]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38/200 | Train Loss: 1.3306 | Val Loss: 1.7031 | Val Acc: 62.19% | LR: 0.000931\n",
            "  ★ New best model saved! Accuracy: 62.19%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/200: 100%|██████████| 390/390 [01:13<00:00,  5.34it/s, loss=0.975]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39/200 | Train Loss: 1.3258 | Val Loss: 1.7703 | Val Acc: 61.09% | LR: 0.000927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/200: 100%|██████████| 390/390 [01:14<00:00,  5.21it/s, loss=0.827]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40/200 | Train Loss: 1.3366 | Val Loss: 1.7632 | Val Acc: 61.73% | LR: 0.000923\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v3_1_dkd_beta2_epoch40.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=3.202]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41/200 | Train Loss: 1.3688 | Val Loss: 1.7715 | Val Acc: 61.42% | LR: 0.000918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.794]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42/200 | Train Loss: 1.3433 | Val Loss: 1.6948 | Val Acc: 61.91% | LR: 0.000914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/200: 100%|██████████| 390/390 [01:13<00:00,  5.33it/s, loss=3.005]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43/200 | Train Loss: 1.4086 | Val Loss: 1.7199 | Val Acc: 63.23% | LR: 0.000909\n",
            "  ★ New best model saved! Accuracy: 63.23%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/200: 100%|██████████| 390/390 [01:13<00:00,  5.33it/s, loss=2.652]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44/200 | Train Loss: 1.3213 | Val Loss: 1.6941 | Val Acc: 63.50% | LR: 0.000905\n",
            "  ★ New best model saved! Accuracy: 63.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/200: 100%|██████████| 390/390 [01:13<00:00,  5.34it/s, loss=0.633]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45/200 | Train Loss: 1.3557 | Val Loss: 1.6997 | Val Acc: 62.26% | LR: 0.000900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.797]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46/200 | Train Loss: 1.4308 | Val Loss: 1.6911 | Val Acc: 63.29% | LR: 0.000895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/200: 100%|██████████| 390/390 [01:12<00:00,  5.35it/s, loss=2.956]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47/200 | Train Loss: 1.3159 | Val Loss: 1.7132 | Val Acc: 62.20% | LR: 0.000890\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.903]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48/200 | Train Loss: 1.3724 | Val Loss: 1.6950 | Val Acc: 62.96% | LR: 0.000885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49/200: 100%|██████████| 390/390 [01:12<00:00,  5.36it/s, loss=0.889]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49/200 | Train Loss: 1.3886 | Val Loss: 1.7178 | Val Acc: 62.53% | LR: 0.000880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.913]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50/200 | Train Loss: 1.3836 | Val Loss: 1.6891 | Val Acc: 63.16% | LR: 0.000874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 51/200: 100%|██████████| 390/390 [01:13<00:00,  5.33it/s, loss=0.794]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51/200 | Train Loss: 1.3390 | Val Loss: 1.6856 | Val Acc: 64.03% | LR: 0.000869\n",
            "  ★ New best model saved! Accuracy: 64.03%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 52/200: 100%|██████████| 390/390 [01:12<00:00,  5.36it/s, loss=0.811]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52/200 | Train Loss: 1.3437 | Val Loss: 1.6720 | Val Acc: 63.06% | LR: 0.000863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 53/200: 100%|██████████| 390/390 [01:13<00:00,  5.33it/s, loss=0.896]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53/200 | Train Loss: 1.3730 | Val Loss: 1.6619 | Val Acc: 64.50% | LR: 0.000858\n",
            "  ★ New best model saved! Accuracy: 64.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 54/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=3.116]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54/200 | Train Loss: 1.2570 | Val Loss: 1.6816 | Val Acc: 63.88% | LR: 0.000852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 55/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=2.025]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55/200 | Train Loss: 1.3388 | Val Loss: 1.6408 | Val Acc: 64.94% | LR: 0.000846\n",
            "  ★ New best model saved! Accuracy: 64.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 56/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=0.874]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56/200 | Train Loss: 1.3244 | Val Loss: 1.7715 | Val Acc: 62.81% | LR: 0.000841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 57/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.836]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57/200 | Train Loss: 1.2430 | Val Loss: 1.6830 | Val Acc: 63.45% | LR: 0.000835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 58/200: 100%|██████████| 390/390 [01:13<00:00,  5.33it/s, loss=0.683]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58/200 | Train Loss: 1.3268 | Val Loss: 1.6249 | Val Acc: 64.75% | LR: 0.000829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 59/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.869]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59/200 | Train Loss: 1.4009 | Val Loss: 1.7031 | Val Acc: 63.47% | LR: 0.000822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 60/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.746]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60/200 | Train Loss: 1.3311 | Val Loss: 1.5981 | Val Acc: 64.90% | LR: 0.000816\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v3_1_dkd_beta2_epoch60.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 61/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=0.922]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 61/200 | Train Loss: 1.3024 | Val Loss: 1.6325 | Val Acc: 64.00% | LR: 0.000810\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 62/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=1.033]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 62/200 | Train Loss: 1.3237 | Val Loss: 1.6703 | Val Acc: 64.27% | LR: 0.000804\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 63/200: 100%|██████████| 390/390 [01:12<00:00,  5.37it/s, loss=0.742]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 63/200 | Train Loss: 1.3131 | Val Loss: 1.6312 | Val Acc: 64.27% | LR: 0.000797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 64/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.824]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 64/200 | Train Loss: 1.3628 | Val Loss: 1.6519 | Val Acc: 64.77% | LR: 0.000791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 65/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.647]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 65/200 | Train Loss: 1.2973 | Val Loss: 1.7233 | Val Acc: 64.45% | LR: 0.000784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 66/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.847]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66/200 | Train Loss: 1.2869 | Val Loss: 1.6619 | Val Acc: 65.04% | LR: 0.000777\n",
            "  ★ New best model saved! Accuracy: 65.04%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 67/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=0.951]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 67/200 | Train Loss: 1.3881 | Val Loss: 1.6216 | Val Acc: 63.91% | LR: 0.000771\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 68/200: 100%|██████████| 390/390 [01:13<00:00,  5.34it/s, loss=0.901]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 68/200 | Train Loss: 1.3028 | Val Loss: 1.5865 | Val Acc: 64.74% | LR: 0.000764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 69/200: 100%|██████████| 390/390 [01:13<00:00,  5.33it/s, loss=2.449]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 69/200 | Train Loss: 1.2936 | Val Loss: 1.5679 | Val Acc: 66.39% | LR: 0.000757\n",
            "  ★ New best model saved! Accuracy: 66.39%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 70/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.813]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70/200 | Train Loss: 1.2464 | Val Loss: 1.6925 | Val Acc: 63.87% | LR: 0.000750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 71/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.873]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 71/200 | Train Loss: 1.2653 | Val Loss: 1.6297 | Val Acc: 66.08% | LR: 0.000743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 72/200: 100%|██████████| 390/390 [01:13<00:00,  5.33it/s, loss=2.366]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 72/200 | Train Loss: 1.2371 | Val Loss: 1.5885 | Val Acc: 65.52% | LR: 0.000736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 73/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=0.628]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 73/200 | Train Loss: 1.3613 | Val Loss: 1.5616 | Val Acc: 65.60% | LR: 0.000729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 74/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.524]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 74/200 | Train Loss: 1.2502 | Val Loss: 1.6018 | Val Acc: 65.81% | LR: 0.000722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 75/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=3.079]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 75/200 | Train Loss: 1.3654 | Val Loss: 1.5904 | Val Acc: 65.15% | LR: 0.000714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 76/200: 100%|██████████| 390/390 [01:12<00:00,  5.34it/s, loss=0.898]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 76/200 | Train Loss: 1.3027 | Val Loss: 1.5923 | Val Acc: 65.53% | LR: 0.000707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 77/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.804]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 77/200 | Train Loss: 1.2179 | Val Loss: 1.6792 | Val Acc: 65.21% | LR: 0.000700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 78/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.797]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 78/200 | Train Loss: 1.3075 | Val Loss: 1.6243 | Val Acc: 65.29% | LR: 0.000692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 79/200: 100%|██████████| 390/390 [01:12<00:00,  5.35it/s, loss=0.852]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 79/200 | Train Loss: 1.3165 | Val Loss: 1.5411 | Val Acc: 66.39% | LR: 0.000685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 80/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.903]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 80/200 | Train Loss: 1.2246 | Val Loss: 1.5963 | Val Acc: 65.41% | LR: 0.000677\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v3_1_dkd_beta2_epoch80.pth\n",
            "  Cleaned up: student_v3_1_dkd_beta2_epoch20.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 81/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.832]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 81/200 | Train Loss: 1.2729 | Val Loss: 1.5618 | Val Acc: 65.63% | LR: 0.000670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 82/200: 100%|██████████| 390/390 [01:13<00:00,  5.33it/s, loss=1.494]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 82/200 | Train Loss: 1.3312 | Val Loss: 1.6459 | Val Acc: 64.95% | LR: 0.000662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 83/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=1.619]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 83/200 | Train Loss: 1.3456 | Val Loss: 1.5811 | Val Acc: 65.86% | LR: 0.000655\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 84/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.766]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 84/200 | Train Loss: 1.2525 | Val Loss: 1.5868 | Val Acc: 66.23% | LR: 0.000647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 85/200: 100%|██████████| 390/390 [01:12<00:00,  5.36it/s, loss=0.591]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 85/200 | Train Loss: 1.2541 | Val Loss: 1.5574 | Val Acc: 66.69% | LR: 0.000639\n",
            "  ★ New best model saved! Accuracy: 66.69%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 86/200: 100%|██████████| 390/390 [01:13<00:00,  5.34it/s, loss=0.829]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 86/200 | Train Loss: 1.2614 | Val Loss: 1.5510 | Val Acc: 65.38% | LR: 0.000631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 87/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.749]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 87/200 | Train Loss: 1.2896 | Val Loss: 1.5880 | Val Acc: 65.93% | LR: 0.000624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 88/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.617]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 88/200 | Train Loss: 1.2950 | Val Loss: 1.5167 | Val Acc: 66.68% | LR: 0.000616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 89/200: 100%|██████████| 390/390 [01:13<00:00,  5.34it/s, loss=0.789]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 89/200 | Train Loss: 1.2372 | Val Loss: 1.5166 | Val Acc: 67.50% | LR: 0.000608\n",
            "  ★ New best model saved! Accuracy: 67.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 90/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.801]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 90/200 | Train Loss: 1.2650 | Val Loss: 1.5462 | Val Acc: 67.32% | LR: 0.000600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 91/200: 100%|██████████| 390/390 [01:13<00:00,  5.34it/s, loss=2.538]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 91/200 | Train Loss: 1.2945 | Val Loss: 1.5384 | Val Acc: 66.39% | LR: 0.000592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 92/200: 100%|██████████| 390/390 [01:12<00:00,  5.36it/s, loss=2.556]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 92/200 | Train Loss: 1.1503 | Val Loss: 1.4519 | Val Acc: 67.40% | LR: 0.000584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 93/200: 100%|██████████| 390/390 [01:13<00:00,  5.33it/s, loss=0.845]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 93/200 | Train Loss: 1.2169 | Val Loss: 1.5400 | Val Acc: 67.57% | LR: 0.000576\n",
            "  ★ New best model saved! Accuracy: 67.57%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 94/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.596]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 94/200 | Train Loss: 1.2370 | Val Loss: 1.5318 | Val Acc: 67.15% | LR: 0.000568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 95/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.619]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 95/200 | Train Loss: 1.2579 | Val Loss: 1.6818 | Val Acc: 65.52% | LR: 0.000560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 96/200: 100%|██████████| 390/390 [01:13<00:00,  5.33it/s, loss=1.604]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 96/200 | Train Loss: 1.2732 | Val Loss: 1.4777 | Val Acc: 68.31% | LR: 0.000552\n",
            "  ★ New best model saved! Accuracy: 68.31%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 97/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=0.658]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 97/200 | Train Loss: 1.3151 | Val Loss: 1.7384 | Val Acc: 65.78% | LR: 0.000544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 98/200: 100%|██████████| 390/390 [01:12<00:00,  5.34it/s, loss=0.703]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 98/200 | Train Loss: 1.1956 | Val Loss: 1.7078 | Val Acc: 66.67% | LR: 0.000536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 99/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=2.210]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 99/200 | Train Loss: 1.2681 | Val Loss: 1.5371 | Val Acc: 67.53% | LR: 0.000528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 100/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=2.918]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100/200 | Train Loss: 1.2645 | Val Loss: 1.5541 | Val Acc: 66.31% | LR: 0.000520\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v3_1_dkd_beta2_epoch100.pth\n",
            "  Cleaned up: student_v3_1_dkd_beta2_epoch100.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 101/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.802]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 101/200 | Train Loss: 1.2527 | Val Loss: 1.9906 | Val Acc: 66.98% | LR: 0.000512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 102/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=2.653]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 102/200 | Train Loss: 1.2873 | Val Loss: 1.8024 | Val Acc: 65.46% | LR: 0.000504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 103/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=1.344]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 103/200 | Train Loss: 1.2829 | Val Loss: 1.7623 | Val Acc: 66.54% | LR: 0.000496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 104/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=0.794]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 104/200 | Train Loss: 1.2095 | Val Loss: 1.5579 | Val Acc: 66.82% | LR: 0.000488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 105/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.790]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 105/200 | Train Loss: 1.2337 | Val Loss: 1.6308 | Val Acc: 67.41% | LR: 0.000480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 106/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.803]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 106/200 | Train Loss: 1.2193 | Val Loss: 1.6777 | Val Acc: 66.39% | LR: 0.000472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 107/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.816]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 107/200 | Train Loss: 1.2457 | Val Loss: 1.5021 | Val Acc: 68.54% | LR: 0.000464\n",
            "  ★ New best model saved! Accuracy: 68.54%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 108/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.761]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 108/200 | Train Loss: 1.2417 | Val Loss: 2.2689 | Val Acc: 67.24% | LR: 0.000456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 109/200: 100%|██████████| 390/390 [01:13<00:00,  5.34it/s, loss=0.530]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 109/200 | Train Loss: 1.2237 | Val Loss: 1.5778 | Val Acc: 67.74% | LR: 0.000448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 110/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=2.363]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 110/200 | Train Loss: 1.1484 | Val Loss: 1.5059 | Val Acc: 67.90% | LR: 0.000440\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 111/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.761]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 111/200 | Train Loss: 1.1333 | Val Loss: 1.5782 | Val Acc: 68.82% | LR: 0.000432\n",
            "  ★ New best model saved! Accuracy: 68.82%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 112/200: 100%|██████████| 390/390 [01:12<00:00,  5.36it/s, loss=1.427]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 112/200 | Train Loss: 1.1883 | Val Loss: 2.5452 | Val Acc: 67.25% | LR: 0.000424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 113/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=3.492]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 113/200 | Train Loss: 1.2059 | Val Loss: 2.1887 | Val Acc: 67.35% | LR: 0.000416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 114/200: 100%|██████████| 390/390 [01:14<00:00,  5.25it/s, loss=0.638]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 114/200 | Train Loss: 1.2091 | Val Loss: 1.9560 | Val Acc: 69.37% | LR: 0.000408\n",
            "  ★ New best model saved! Accuracy: 69.37%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 115/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.747]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 115/200 | Train Loss: 1.1787 | Val Loss: 2.6276 | Val Acc: 68.71% | LR: 0.000400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 116/200: 100%|██████████| 390/390 [01:13<00:00,  5.33it/s, loss=0.508]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 116/200 | Train Loss: 1.1702 | Val Loss: 1.5897 | Val Acc: 68.75% | LR: 0.000392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 117/200: 100%|██████████| 390/390 [01:13<00:00,  5.27it/s, loss=2.226]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 117/200 | Train Loss: 1.1738 | Val Loss: 1.3981 | Val Acc: 69.35% | LR: 0.000384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 118/200: 100%|██████████| 390/390 [01:12<00:00,  5.35it/s, loss=0.640]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 118/200 | Train Loss: 1.2094 | Val Loss: 1.6214 | Val Acc: 69.46% | LR: 0.000376\n",
            "  ★ New best model saved! Accuracy: 69.46%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 119/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=0.700]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 119/200 | Train Loss: 1.1960 | Val Loss: 1.5460 | Val Acc: 69.12% | LR: 0.000369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 120/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.816]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 120/200 | Train Loss: 1.1653 | Val Loss: 1.8231 | Val Acc: 68.34% | LR: 0.000361\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v3_1_dkd_beta2_epoch120.pth\n",
            "  Cleaned up: student_v3_1_dkd_beta2_epoch120.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 121/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=0.490]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 121/200 | Train Loss: 1.2463 | Val Loss: 1.4859 | Val Acc: 68.71% | LR: 0.000353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 122/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.814]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 122/200 | Train Loss: 1.2002 | Val Loss: 1.5196 | Val Acc: 69.07% | LR: 0.000345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 123/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.720]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 123/200 | Train Loss: 1.1487 | Val Loss: 2.5122 | Val Acc: 68.66% | LR: 0.000338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 124/200: 100%|██████████| 390/390 [01:13<00:00,  5.27it/s, loss=0.668]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 124/200 | Train Loss: 1.2188 | Val Loss: 1.4477 | Val Acc: 69.97% | LR: 0.000330\n",
            "  ★ New best model saved! Accuracy: 69.97%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 125/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.711]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 125/200 | Train Loss: 1.1168 | Val Loss: 1.5111 | Val Acc: 69.31% | LR: 0.000323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 126/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.766]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 126/200 | Train Loss: 1.1469 | Val Loss: 1.5291 | Val Acc: 68.94% | LR: 0.000315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 127/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=1.979]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 127/200 | Train Loss: 1.2199 | Val Loss: 1.3985 | Val Acc: 70.13% | LR: 0.000308\n",
            "  ★ New best model saved! Accuracy: 70.13%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 128/200: 100%|██████████| 390/390 [01:14<00:00,  5.27it/s, loss=0.709]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 128/200 | Train Loss: 1.1360 | Val Loss: 1.3872 | Val Acc: 70.50% | LR: 0.000300\n",
            "  ★ New best model saved! Accuracy: 70.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 129/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.762]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 129/200 | Train Loss: 1.1528 | Val Loss: 1.4230 | Val Acc: 70.27% | LR: 0.000293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 130/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.614]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 130/200 | Train Loss: 1.1641 | Val Loss: 1.4337 | Val Acc: 71.09% | LR: 0.000286\n",
            "  ★ New best model saved! Accuracy: 71.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 131/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=2.365]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 131/200 | Train Loss: 1.1608 | Val Loss: 1.4394 | Val Acc: 70.16% | LR: 0.000278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 132/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=0.607]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 132/200 | Train Loss: 1.1391 | Val Loss: 1.3988 | Val Acc: 70.63% | LR: 0.000271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 133/200: 100%|██████████| 390/390 [01:12<00:00,  5.34it/s, loss=1.949]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 133/200 | Train Loss: 1.1780 | Val Loss: 1.3668 | Val Acc: 71.11% | LR: 0.000264\n",
            "  ★ New best model saved! Accuracy: 71.11%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 134/200: 100%|██████████| 390/390 [01:13<00:00,  5.32it/s, loss=0.792]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 134/200 | Train Loss: 1.1192 | Val Loss: 1.3953 | Val Acc: 70.81% | LR: 0.000257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 135/200: 100%|██████████| 390/390 [01:15<00:00,  5.19it/s, loss=0.691]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 135/200 | Train Loss: 1.1604 | Val Loss: 1.6678 | Val Acc: 70.48% | LR: 0.000250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 136/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=1.149]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 136/200 | Train Loss: 1.1073 | Val Loss: 1.4702 | Val Acc: 70.43% | LR: 0.000243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 137/200: 100%|██████████| 390/390 [01:14<00:00,  5.25it/s, loss=0.626]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 137/200 | Train Loss: 1.1152 | Val Loss: 1.6495 | Val Acc: 70.09% | LR: 0.000236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 138/200: 100%|██████████| 390/390 [01:14<00:00,  5.24it/s, loss=0.676]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 138/200 | Train Loss: 1.1570 | Val Loss: 1.7968 | Val Acc: 70.47% | LR: 0.000229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 139/200: 100%|██████████| 390/390 [01:14<00:00,  5.23it/s, loss=0.744]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 139/200 | Train Loss: 1.1445 | Val Loss: 1.4114 | Val Acc: 70.78% | LR: 0.000223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 140/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=0.651]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 140/200 | Train Loss: 1.1083 | Val Loss: 1.4549 | Val Acc: 70.99% | LR: 0.000216\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v3_1_dkd_beta2_epoch140.pth\n",
            "  Cleaned up: student_v3_1_dkd_beta2_epoch140.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 141/200: 100%|██████████| 390/390 [01:14<00:00,  5.22it/s, loss=2.084]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 141/200 | Train Loss: 1.1818 | Val Loss: 1.3315 | Val Acc: 71.41% | LR: 0.000209\n",
            "  ★ New best model saved! Accuracy: 71.41%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 142/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=3.529]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 142/200 | Train Loss: 1.1090 | Val Loss: 1.4386 | Val Acc: 71.12% | LR: 0.000203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 143/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.581]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 143/200 | Train Loss: 1.0924 | Val Loss: 1.3979 | Val Acc: 71.93% | LR: 0.000196\n",
            "  ★ New best model saved! Accuracy: 71.93%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 144/200: 100%|██████████| 390/390 [01:14<00:00,  5.25it/s, loss=0.714]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 144/200 | Train Loss: 1.1658 | Val Loss: 1.5252 | Val Acc: 71.41% | LR: 0.000190\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 145/200: 100%|██████████| 390/390 [01:13<00:00,  5.27it/s, loss=1.763]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 145/200 | Train Loss: 1.1557 | Val Loss: 1.4070 | Val Acc: 71.33% | LR: 0.000184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 146/200: 100%|██████████| 390/390 [01:14<00:00,  5.24it/s, loss=0.546]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 146/200 | Train Loss: 1.1801 | Val Loss: 1.4952 | Val Acc: 70.75% | LR: 0.000178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 147/200: 100%|██████████| 390/390 [01:14<00:00,  5.25it/s, loss=1.387]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 147/200 | Train Loss: 1.1292 | Val Loss: 1.4213 | Val Acc: 71.42% | LR: 0.000171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 148/200: 100%|██████████| 390/390 [01:14<00:00,  5.24it/s, loss=0.465]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 148/200 | Train Loss: 1.0911 | Val Loss: 1.2900 | Val Acc: 72.26% | LR: 0.000165\n",
            "  ★ New best model saved! Accuracy: 72.26%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 149/200: 100%|██████████| 390/390 [01:14<00:00,  5.25it/s, loss=0.567]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 149/200 | Train Loss: 1.1181 | Val Loss: 1.6638 | Val Acc: 71.33% | LR: 0.000159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 150/200: 100%|██████████| 390/390 [01:14<00:00,  5.21it/s, loss=3.361]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 150/200 | Train Loss: 1.0836 | Val Loss: 1.4503 | Val Acc: 71.98% | LR: 0.000154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 151/200: 100%|██████████| 390/390 [01:14<00:00,  5.23it/s, loss=0.823]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 151/200 | Train Loss: 1.1040 | Val Loss: 2.4681 | Val Acc: 70.25% | LR: 0.000148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 152/200: 100%|██████████| 390/390 [01:14<00:00,  5.23it/s, loss=0.598]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 152/200 | Train Loss: 1.0587 | Val Loss: 1.3561 | Val Acc: 72.16% | LR: 0.000142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 153/200: 100%|██████████| 390/390 [01:14<00:00,  5.20it/s, loss=1.316]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 153/200 | Train Loss: 1.1071 | Val Loss: 1.6214 | Val Acc: 71.54% | LR: 0.000137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 154/200: 100%|██████████| 390/390 [01:14<00:00,  5.22it/s, loss=0.753]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 154/200 | Train Loss: 1.1481 | Val Loss: 1.5115 | Val Acc: 71.71% | LR: 0.000131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 155/200: 100%|██████████| 390/390 [01:14<00:00,  5.24it/s, loss=0.455]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 155/200 | Train Loss: 1.0890 | Val Loss: 1.4686 | Val Acc: 72.01% | LR: 0.000126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 156/200: 100%|██████████| 390/390 [01:13<00:00,  5.27it/s, loss=0.445]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 156/200 | Train Loss: 1.0990 | Val Loss: 1.3467 | Val Acc: 72.30% | LR: 0.000120\n",
            "  ★ New best model saved! Accuracy: 72.30%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 157/200: 100%|██████████| 390/390 [01:14<00:00,  5.23it/s, loss=0.709]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 157/200 | Train Loss: 1.0744 | Val Loss: 1.7305 | Val Acc: 71.78% | LR: 0.000115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 158/200: 100%|██████████| 390/390 [01:13<00:00,  5.27it/s, loss=0.716]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 158/200 | Train Loss: 1.0482 | Val Loss: 1.3701 | Val Acc: 72.53% | LR: 0.000110\n",
            "  ★ New best model saved! Accuracy: 72.53%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 159/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.655]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 159/200 | Train Loss: 1.0916 | Val Loss: 1.6118 | Val Acc: 72.08% | LR: 0.000105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 160/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=3.050]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 160/200 | Train Loss: 1.0678 | Val Loss: 1.3506 | Val Acc: 72.61% | LR: 0.000100\n",
            "  ★ New best model saved! Accuracy: 72.61%\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v3_1_dkd_beta2_epoch160.pth\n",
            "  Cleaned up: student_v3_1_dkd_beta2_epoch160.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 161/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=0.414]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 161/200 | Train Loss: 1.1204 | Val Loss: 1.3496 | Val Acc: 72.79% | LR: 0.000095\n",
            "  ★ New best model saved! Accuracy: 72.79%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 162/200: 100%|██████████| 390/390 [01:13<00:00,  5.27it/s, loss=2.200]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 162/200 | Train Loss: 1.2001 | Val Loss: 1.3384 | Val Acc: 73.23% | LR: 0.000091\n",
            "  ★ New best model saved! Accuracy: 73.23%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 163/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=0.513]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 163/200 | Train Loss: 1.0926 | Val Loss: 1.2753 | Val Acc: 73.22% | LR: 0.000086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 164/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=2.497]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 164/200 | Train Loss: 1.0940 | Val Loss: 1.3488 | Val Acc: 73.19% | LR: 0.000082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 165/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=3.518]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 165/200 | Train Loss: 1.1133 | Val Loss: 2.0715 | Val Acc: 72.13% | LR: 0.000077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 166/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=1.014]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 166/200 | Train Loss: 1.1191 | Val Loss: 1.3418 | Val Acc: 73.18% | LR: 0.000073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 167/200: 100%|██████████| 390/390 [01:14<00:00,  5.22it/s, loss=0.412]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 167/200 | Train Loss: 1.0902 | Val Loss: 1.2552 | Val Acc: 73.48% | LR: 0.000069\n",
            "  ★ New best model saved! Accuracy: 73.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 168/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=0.473]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 168/200 | Train Loss: 1.0506 | Val Loss: 1.3756 | Val Acc: 73.02% | LR: 0.000065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 169/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=0.538]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 169/200 | Train Loss: 1.1058 | Val Loss: 1.4782 | Val Acc: 72.83% | LR: 0.000061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 170/200: 100%|██████████| 390/390 [01:14<00:00,  5.25it/s, loss=0.663]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 170/200 | Train Loss: 1.0775 | Val Loss: 1.4037 | Val Acc: 73.40% | LR: 0.000057\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 171/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=0.586]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 171/200 | Train Loss: 1.0693 | Val Loss: 1.3976 | Val Acc: 72.86% | LR: 0.000054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 172/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=0.553]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 172/200 | Train Loss: 1.0227 | Val Loss: 1.4470 | Val Acc: 72.96% | LR: 0.000050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 173/200: 100%|██████████| 390/390 [01:13<00:00,  5.31it/s, loss=0.467]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 173/200 | Train Loss: 1.0382 | Val Loss: 1.2465 | Val Acc: 73.60% | LR: 0.000047\n",
            "  ★ New best model saved! Accuracy: 73.60%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 174/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=0.409]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 174/200 | Train Loss: 0.9822 | Val Loss: 1.3117 | Val Acc: 73.48% | LR: 0.000043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 175/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=0.703]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 175/200 | Train Loss: 1.0661 | Val Loss: 1.4264 | Val Acc: 73.22% | LR: 0.000040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 176/200: 100%|██████████| 390/390 [01:14<00:00,  5.24it/s, loss=0.701]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 176/200 | Train Loss: 1.0489 | Val Loss: 1.4557 | Val Acc: 73.60% | LR: 0.000037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 177/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.691]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 177/200 | Train Loss: 1.0717 | Val Loss: 1.4569 | Val Acc: 73.08% | LR: 0.000034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 178/200: 100%|██████████| 390/390 [01:14<00:00,  5.27it/s, loss=0.526]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 178/200 | Train Loss: 1.0109 | Val Loss: 1.4018 | Val Acc: 73.78% | LR: 0.000031\n",
            "  ★ New best model saved! Accuracy: 73.78%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 179/200: 100%|██████████| 390/390 [01:13<00:00,  5.30it/s, loss=0.700]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 179/200 | Train Loss: 1.1420 | Val Loss: 1.2828 | Val Acc: 73.73% | LR: 0.000028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 180/200: 100%|██████████| 390/390 [01:14<00:00,  5.27it/s, loss=0.399]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 180/200 | Train Loss: 1.0247 | Val Loss: 1.3125 | Val Acc: 73.61% | LR: 0.000026\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v3_1_dkd_beta2_epoch180.pth\n",
            "  Cleaned up: student_v3_1_dkd_beta2_epoch180.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 181/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=0.705]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 181/200 | Train Loss: 1.0289 | Val Loss: 1.4978 | Val Acc: 72.81% | LR: 0.000023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 182/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=0.692]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 182/200 | Train Loss: 1.0376 | Val Loss: 1.5420 | Val Acc: 73.04% | LR: 0.000021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 183/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=0.399]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 183/200 | Train Loss: 1.0719 | Val Loss: 1.4947 | Val Acc: 73.32% | LR: 0.000019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 184/200: 100%|██████████| 390/390 [01:14<00:00,  5.24it/s, loss=0.550]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 184/200 | Train Loss: 1.0535 | Val Loss: 1.3238 | Val Acc: 73.50% | LR: 0.000017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 185/200: 100%|██████████| 390/390 [01:14<00:00,  5.24it/s, loss=3.417]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 185/200 | Train Loss: 1.0362 | Val Loss: 1.3997 | Val Acc: 73.41% | LR: 0.000015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 186/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=0.660]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 186/200 | Train Loss: 1.0540 | Val Loss: 1.2796 | Val Acc: 73.98% | LR: 0.000013\n",
            "  ★ New best model saved! Accuracy: 73.98%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 187/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=1.757]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 187/200 | Train Loss: 1.0241 | Val Loss: 1.3191 | Val Acc: 73.71% | LR: 0.000011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 188/200: 100%|██████████| 390/390 [01:14<00:00,  5.24it/s, loss=1.793]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 188/200 | Train Loss: 0.9912 | Val Loss: 1.3611 | Val Acc: 73.43% | LR: 0.000009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 189/200: 100%|██████████| 390/390 [01:13<00:00,  5.27it/s, loss=2.282]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 189/200 | Train Loss: 1.0432 | Val Loss: 1.5905 | Val Acc: 73.32% | LR: 0.000008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 190/200: 100%|██████████| 390/390 [01:14<00:00,  5.24it/s, loss=0.438]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 190/200 | Train Loss: 0.9985 | Val Loss: 1.3640 | Val Acc: 73.43% | LR: 0.000006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 191/200: 100%|██████████| 390/390 [01:14<00:00,  5.24it/s, loss=0.639]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 191/200 | Train Loss: 1.0797 | Val Loss: 1.3120 | Val Acc: 73.69% | LR: 0.000005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 192/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=0.420]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 192/200 | Train Loss: 0.9801 | Val Loss: 1.2683 | Val Acc: 73.82% | LR: 0.000004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 193/200: 100%|██████████| 390/390 [01:13<00:00,  5.27it/s, loss=0.595]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 193/200 | Train Loss: 1.0271 | Val Loss: 1.4089 | Val Acc: 73.31% | LR: 0.000003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 194/200: 100%|██████████| 390/390 [01:14<00:00,  5.20it/s, loss=0.707]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 194/200 | Train Loss: 1.0315 | Val Loss: 1.4823 | Val Acc: 73.40% | LR: 0.000002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 195/200: 100%|██████████| 390/390 [01:13<00:00,  5.29it/s, loss=3.483]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 195/200 | Train Loss: 1.0199 | Val Loss: 1.2919 | Val Acc: 73.80% | LR: 0.000002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 196/200: 100%|██████████| 390/390 [01:13<00:00,  5.28it/s, loss=0.497]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 196/200 | Train Loss: 1.0648 | Val Loss: 1.4802 | Val Acc: 73.57% | LR: 0.000001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 197/200: 100%|██████████| 390/390 [01:14<00:00,  5.25it/s, loss=2.159]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 197/200 | Train Loss: 1.0852 | Val Loss: 1.3730 | Val Acc: 73.55% | LR: 0.000001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 198/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=0.570]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 198/200 | Train Loss: 1.0429 | Val Loss: 1.4996 | Val Acc: 73.04% | LR: 0.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 199/200: 100%|██████████| 390/390 [01:13<00:00,  5.27it/s, loss=0.502]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 199/200 | Train Loss: 1.0405 | Val Loss: 1.2395 | Val Acc: 73.95% | LR: 0.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 200/200: 100%|██████████| 390/390 [01:14<00:00,  5.26it/s, loss=2.992]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200/200 | Train Loss: 1.0202 | Val Loss: 1.3270 | Val Acc: 73.83% | LR: 0.000000\n",
            "  Checkpoint saved: outputs\\checkpoints\\student_v3_1_dkd_beta2_epoch200.pth\n",
            "  Cleaned up: student_v3_1_dkd_beta2_epoch200.pth\n",
            "\n",
            "==================================================\n",
            "Training complete. Best accuracy: 73.98%\n",
            "==================================================\n",
            "\n",
            "Student v3.1 (DKD β=2.0) Final Accuracy: 73.98%\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Train Student with DKD (Version 3.1 - Tuned Beta)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STUDENT MODEL with DKD (Version 3.1 - Tuned Beta)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "student_path = MODEL_DIR / f\"{STUDENT_NAME}.pth\"\n",
        "\n",
        "if student_path.exists():\n",
        "    print(f\"Found existing Student v3.1: {student_path}\")\n",
        "    student_model.load_state_dict(torch.load(student_path, map_location=device))\n",
        "    distilled_accuracy, _ = evaluate_model_with_loss(student_model, testloader, nn.CrossEntropyLoss())\n",
        "    print(f\"Student v3.1 (DKD β=2.0) Accuracy: {distilled_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(f\"\\nStarting Decoupled Knowledge Distillation (DKD) v3.1...\")\n",
        "    print(f\"  Key Change: DKD Beta REDUCED from 8.0 to {DKD_BETA}\")\n",
        "    print(f\"  DKD Alpha (TCKD weight): {DKD_ALPHA}\")\n",
        "    print(f\"  DKD Beta (NCKD weight): {DKD_BETA} ← REDUCED to fix over-regularization\")\n",
        "    print(f\"  Temperature: {TEMPERATURE}\")\n",
        "    print(f\"  Label Smoothing: {LABEL_SMOOTHING}\")\n",
        "    print(f\"  LR Warmup: {WARMUP_EPOCHS} epochs\")\n",
        "    print(f\"  Augmentation: AutoAugment + RandomErasing + CutMix/Mixup\")\n",
        "    \n",
        "    # Re-initialize student model (fresh weights from ImageNet)\n",
        "    student_model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
        "    student_model.classifier[1] = nn.Linear(student_model.classifier[1].in_features, NUM_CLASSES)\n",
        "    student_model = student_model.to(device)\n",
        "    \n",
        "    # Optimizer & Scheduler\n",
        "    opt_s = optim.AdamW(student_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    sch_s = optim.lr_scheduler.CosineAnnealingLR(opt_s, T_max=NUM_EPOCHS - WARMUP_EPOCHS)\n",
        "    \n",
        "    # Run DKD Training with tuned beta\n",
        "    trained_student, distilled_history = train_model_v3(\n",
        "        model=student_model,\n",
        "        dataloader=trainloader,\n",
        "        optimizer=opt_s,\n",
        "        scheduler=sch_s,\n",
        "        num_epochs=NUM_EPOCHS,\n",
        "        model_name=STUDENT_NAME,\n",
        "        teacher_model=teacher_model,\n",
        "        use_dkd=True,  # Enable DKD loss\n",
        "        dkd_alpha=DKD_ALPHA,\n",
        "        dkd_beta=DKD_BETA,  # Now 2.0 instead of 8.0\n",
        "        temperature=TEMPERATURE,\n",
        "        label_smoothing=LABEL_SMOOTHING,\n",
        "        patience=PATIENCE,\n",
        "        warmup_epochs=WARMUP_EPOCHS\n",
        "    )\n",
        "    \n",
        "    distilled_accuracy, _ = evaluate_model_with_loss(trained_student, testloader, nn.CrossEntropyLoss())\n",
        "    print(f\"\\nStudent v3.1 (DKD β=2.0) Final Accuracy: {distilled_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "VERSION 3.1 RESULTS SUMMARY - Tuned DKD (Beta=2.0)\n",
            "================================================================================\n",
            "\n",
            "┌─────────────────────────────────────────────────────────────────────┐\n",
            "│                    MODEL COMPARISON TABLE                           │\n",
            "├──────────────────────────────┬──────────────┬───────────────────────┤\n",
            "│ Model                        │ Accuracy (%) │ Notes                 │\n",
            "├──────────────────────────────┼──────────────┼───────────────────────┤\n",
            "│ Teacher v3 (EfficientNet-L)  │        76.02 │ Extended training     │\n",
            "│ Student v3.1 DKD β=2.0       │        73.98 │ Tuned NCKD weight     │\n",
            "├──────────────────────────────┴──────────────┴───────────────────────┤\n",
            "│                    PREVIOUS VERSIONS (for comparison)              │\n",
            "├──────────────────────────────┬──────────────┬───────────────────────┤\n",
            "│ Student v1 (Baseline)        │        72.34 │ Standard KD           │\n",
            "│ Student v2 (Enhanced)        │        74.20 │ + AutoAug + Warmup    │\n",
            "│ Student v3 (DKD β=8.0)       │        72.69 │ Over-regularized      │\n",
            "└──────────────────────────────┴──────────────┴───────────────────────┘\n",
            "\n",
            "================================================================================\n",
            "VERSION 3.1 ANALYSIS:\n",
            "  Teacher v3 Accuracy:       76.02%\n",
            "  Student v3.1 Accuracy:     73.98%\n",
            "  Gap from Teacher:          -2.04%\n",
            "  Teacher Retention:         97.3%\n",
            "\n",
            "  Improvement over v3 (β=8.0): +1.29%\n",
            "================================================================================\n",
            "\n",
            "Version 3.1 Key Change:\n",
            "  ✓ DKD Beta REDUCED: 8.0 → 2.0\n",
            "  ✓ Hypothesis: Less aggressive NCKD reduces over-regularization\n",
            "  ✓ Expected: Better balance with Mixup/CutMix augmentation\n",
            "\n",
            "Model Files:\n",
            "  Teacher v3:   outputs\\models\\teacher_v3.pth\n",
            "  Student v3.1: outputs\\models\\student_v3_1_dkd_beta2.pth\n",
            "\n",
            "Checkpoints: d:\\Projects\\MasterProject\\code\\outputs\\checkpoints\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Results Summary (Version 3.1)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"VERSION 3.1 RESULTS SUMMARY - Tuned DKD (Beta=2.0)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Evaluate all available models for comparison\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"\\n┌─────────────────────────────────────────────────────────────────────┐\")\n",
        "print(\"│                    MODEL COMPARISON TABLE                           │\")\n",
        "print(\"├──────────────────────────────┬──────────────┬───────────────────────┤\")\n",
        "print(\"│ Model                        │ Accuracy (%) │ Notes                 │\")\n",
        "print(\"├──────────────────────────────┼──────────────┼───────────────────────┤\")\n",
        "\n",
        "# Teacher v3\n",
        "try:\n",
        "    print(f\"│ Teacher v3 (EfficientNet-L)  │ {teacher_accuracy:12.2f} │ Extended training     │\")\n",
        "except NameError:\n",
        "    print(f\"│ Teacher v3 (EfficientNet-L)  │ {'N/A':>12} │                       │\")\n",
        "\n",
        "# Student v3.1 (DKD with tuned beta)\n",
        "try:\n",
        "    print(f\"│ Student v3.1 DKD β=2.0       │ {distilled_accuracy:12.2f} │ Tuned NCKD weight     │\")\n",
        "except NameError:\n",
        "    print(f\"│ Student v3.1 DKD β=2.0       │ {'N/A':>12} │                       │\")\n",
        "\n",
        "print(\"├──────────────────────────────┴──────────────┴───────────────────────┤\")\n",
        "print(\"│                    PREVIOUS VERSIONS (for comparison)              │\")\n",
        "print(\"├──────────────────────────────┬──────────────┬───────────────────────┤\")\n",
        "print(\"│ Student v1 (Baseline)        │        72.34 │ Standard KD           │\")\n",
        "print(\"│ Student v2 (Enhanced)        │        74.20 │ + AutoAug + Warmup    │\")\n",
        "print(\"│ Student v3 (DKD β=8.0)       │        72.69 │ Over-regularized      │\")\n",
        "print(\"└──────────────────────────────┴──────────────┴───────────────────────┘\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"VERSION 3.1 ANALYSIS:\")\n",
        "try:\n",
        "    gap = distilled_accuracy - teacher_accuracy\n",
        "    retention = (distilled_accuracy / teacher_accuracy) * 100\n",
        "    print(f\"  Teacher v3 Accuracy:       {teacher_accuracy:.2f}%\")\n",
        "    print(f\"  Student v3.1 Accuracy:     {distilled_accuracy:.2f}%\")\n",
        "    print(f\"  Gap from Teacher:          {gap:+.2f}%\")\n",
        "    print(f\"  Teacher Retention:         {retention:.1f}%\")\n",
        "    \n",
        "    # Compare with v3\n",
        "    v3_accuracy = 72.69\n",
        "    improvement = distilled_accuracy - v3_accuracy\n",
        "    print(f\"\\n  Improvement over v3 (β=8.0): {improvement:+.2f}%\")\n",
        "except NameError:\n",
        "    print(\"  Run training cells first to see results.\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nVersion 3.1 Key Change:\")\n",
        "print(f\"  ✓ DKD Beta REDUCED: 8.0 → {DKD_BETA}\")\n",
        "print(f\"  ✓ Hypothesis: Less aggressive NCKD reduces over-regularization\")\n",
        "print(f\"  ✓ Expected: Better balance with Mixup/CutMix augmentation\")\n",
        "\n",
        "print(f\"\\nModel Files:\")\n",
        "print(f\"  Teacher v3:   {MODEL_DIR / TEACHER_NAME}.pth\")\n",
        "print(f\"  Student v3.1: {MODEL_DIR / STUDENT_NAME}.pth\")\n",
        "print(f\"\\nCheckpoints: {CHECKPOINT_DIR.absolute()}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "my-gpu-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
